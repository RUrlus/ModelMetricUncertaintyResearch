{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bea5e9f1",
   "metadata": {},
   "source": [
    "# Dirichlet multinomial\n",
    "\n",
    "Evaluate estimates distributions using Dirichlet-Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae8f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d947a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import mmur\n",
    "import mmu\n",
    "from mmur import DirichletMultinomialConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2895bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['text.color'] = 'black'\n",
    "plt.rcParams['figure.max_open_warning'] = 0\n",
    "COLORS = [i['color'] for i in plt.rcParams['axes.prop_cycle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85628f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_distributions(estimated_metrics, gt_metrics, coverage=None):\n",
    "    fig, axs = plt.subplots(ncols=5, figsize=(25, 5))\n",
    "    for i, c in enumerate(estimated_metrics.columns):\n",
    "        sns.kdeplot(estimated_metrics[c], ax=axs[i], label='estimated')\n",
    "        if coverage is not None:\n",
    "            sns.kdeplot(coverage[c], ax=axs[i], label='simulated')\n",
    "        axs[i].axvline(gt_metrics[c][0], c='grey', lw=2, ls='--', label='population mean')\n",
    "    axs[0].legend()\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7464c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_metrics = [\n",
    "    'neg.precision', 'pos.precision', 'neg.recall', 'pos.recall', 'mcc'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b86601",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "\n",
    "Generate data from a Logistic process with noise\n",
    "\n",
    "#### Hold-out set\n",
    "\n",
    "Validate the model by comparing the credible interval of the samples from the model and unseen data sampled from the data generating process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = mmur.LogisticGenerator()\n",
    "outp = generator.fit_transform(\n",
    "    train_samples=10000,\n",
    "    test_samples=10000,\n",
    "    holdout_samples=10000,\n",
    "    noise_sigma=0.3,\n",
    "    #enable_noise=True,\n",
    "    random_state=123456\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0989a709",
   "metadata": {},
   "source": [
    "Select the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ee9fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = outp['test']['y']\n",
    "probas_test = outp['test']['proba']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da34855",
   "metadata": {},
   "source": [
    "Compute the confusion matrix on the test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc442a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conf_mat, test_metrics = mmu.binary_metrics(\n",
    "    y_test, scores=probas_test, threshold=0.5\n",
    ")\n",
    "test_conf_mat = test_conf_mat.flatten()\n",
    "test_metrics = mmu.metrics_to_dataframe(test_metrics)[target_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddfc19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmu.confusion_matrix_to_dataframe(test_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d0c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10ebd3e",
   "metadata": {},
   "source": [
    "### Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c521d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_proba_test = outp['ground_truth']['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7869f0b",
   "metadata": {},
   "source": [
    "Compute the ground truth confusion matrix and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d8d02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_conf_mat, gt_metrics = mmu.binary_metrics(\n",
    "    y_test, scores=gt_proba_test, threshold=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164a83c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmu.confusion_matrix_to_dataframe(gt_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90188923",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_metrics = mmu.metrics_to_dataframe(gt_metrics)[target_metrics]\n",
    "gt_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16241cd7",
   "metadata": {},
   "source": [
    "### Hold-out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd37abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_holdout = outp['holdout']['y']\n",
    "proba_holdout = outp['holdout']['proba']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b315c3",
   "metadata": {},
   "source": [
    "Compute metrics on this set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_conf_mat, holdout_metrics = mmu.binary_metrics_runs(\n",
    "    y=y_holdout, scores=proba_holdout, threshold=0.5\n",
    ")\n",
    "holdout_metrics = mmu.metrics_to_dataframe(holdout_metrics)[target_metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc688684",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a639afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_model = DirichletMultinomialConfusionMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd981cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = dm_model.fit_predict(\n",
    "    test_conf_mat,\n",
    "    n_samples=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb053da2",
   "metadata": {},
   "source": [
    "### Prior traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ee4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = dm_model.plot_prior_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a512f7b6",
   "metadata": {},
   "source": [
    "### Posterior traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5291955",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = dm_model.plot_posterior_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a8618",
   "metadata": {},
   "source": [
    "### Generative posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e97b8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = dm_model.plot_posterior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b4ffb",
   "metadata": {},
   "source": [
    "### Estimated metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fe6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtr = mmu.metrics_to_dataframe(\n",
    "    dm_model.compute_metrics(metrics=target_metrics),\n",
    "    target_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d1ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_metric_distributions(mtr, gt_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e0490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.pairplot(mtr, diag_kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02ccee1",
   "metadata": {},
   "source": [
    "### Compute Highest Density Interval (HDI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f79c834",
   "metadata": {},
   "source": [
    "#### Predictive samples from Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134335bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_model.posterior_predictive_hdi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd6abea",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = dm_model.plot_hdi_predictive_posterior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4676a17b",
   "metadata": {},
   "source": [
    "#### Metrics based on Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3364f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = dm_model.plot_hdi(metrics=['pos.prec', 'pos.rec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff91f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = dm_model.plot_hdi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6661a6f7",
   "metadata": {},
   "source": [
    "### Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fe48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_metrics_moments = pd.concat(\n",
    "    (\n",
    "        holdout_metrics.apply([np.min, np.max, np.mean]).T,\n",
    "         mmur.stats.compute_hdi(holdout_metrics)\n",
    "    ), axis=1\n",
    ")\n",
    "holdout_metrics_moments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bfeb16",
   "metadata": {},
   "source": [
    "HDI estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e16db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdi_estimates = mmur.stats.compute_hdi(mtr)\n",
    "hdi_estimates['mu'] = mtr.values.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e67a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdi_estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ef068",
   "metadata": {},
   "source": [
    "## Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_counts = ((holdout_metrics - hdi_estimates['lb'].T) < 0.0).sum().to_frame()\n",
    "coverage_counts.columns = ['<lb']\n",
    "coverage_counts['>ub'] = ((holdout_metrics - hdi_estimates['ub'].T) > 0.0).sum()\n",
    "\n",
    "coverage_counts['under_coverage'] = coverage_counts.sum(1)\n",
    "\n",
    "coverage_counts['under_coverage_perc'] = (\n",
    "    (coverage_counts['under_coverage'] / holdout_metrics.shape[0])\n",
    "    * 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe89418",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d2f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mmur.viz.dists.plot_hdis_violin(hdi_estimates, holdout_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b848b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(50, 10), ncols=5, sharey=True)\n",
    "for i, idx in enumerate(hdi_estimates.index):\n",
    "    ax = axs[i]\n",
    "    sns.kdeplot(\n",
    "        mtr[idx],\n",
    "        clip=(mtr[idx].min(), mtr[idx].max()),\n",
    "        ax=ax,\n",
    "        label='estimated',\n",
    "        color=COLORS[0]\n",
    "    )\n",
    "    x, y = ax.get_lines()[0].get_data()\n",
    "    shade_idx = (x > hdi_estimates.loc[idx, 'lb']) & (x < hdi_estimates.loc[idx, 'ub'])\n",
    "    ax.fill_between(\n",
    "        x=x[shade_idx],\n",
    "        y1=y[shade_idx],\n",
    "        alpha=0.3,\n",
    "        label='HDI estimate',\n",
    "        color=COLORS[0]\n",
    "    )\n",
    "\n",
    "    ax.axvline(\n",
    "        x=holdout_metrics_moments.loc[idx, 'lb'],\n",
    "        color=COLORS[1],\n",
    "        ls='--',\n",
    "        label='HDI hold-out'\n",
    "    )\n",
    "    ax.axvline(x=holdout_metrics_moments.loc[idx, 'ub'], color=COLORS[1], ls='--')\n",
    "    ax.axvline(\n",
    "        x=holdout_metrics_moments.loc[idx, 'amin'],\n",
    "        color=COLORS[3],\n",
    "        ls='dotted',\n",
    "        lw=3,\n",
    "        label='range hold-out'\n",
    "    )\n",
    "    ax.axvline(x=holdout_metrics_moments.loc[idx, 'amax'], color=COLORS[3], ls='dotted', lw=3)\n",
    "    ax.legend()\n",
    "    ax.set_ylabel('density', fontsize=16)\n",
    "    ax.set_xlabel(idx, fontsize=18)\n",
    "    ax.tick_params(labelsize=14)\n",
    "    ax.legend(fontsize=16);\n",
    "    fig.suptitle('Estimated vs observed out-of-sample performance', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb1182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
