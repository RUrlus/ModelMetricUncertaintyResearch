{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d150d91",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b5ff67",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import phik\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.stats as sts\n",
    "import scipy.special as ssp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708ad71b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import mmu\n",
    "from mmur import ModelGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f77ade",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['text.color'] = 'black'\n",
    "plt.rcParams['figure.max_open_warning'] = 0\n",
    "COLORS = [i['color'] for i in plt.rcParams['axes.prop_cycle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe0404",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_probas(probas, ground_truth, probas_alt=None, fig=None, axs=None):\n",
    "    if axs is None:\n",
    "        fig, axs = plt.subplots(figsize=(14, 7), nrows=1, ncols=2)\n",
    "\n",
    "    for i in range(probas.shape[1]):\n",
    "        axs[0].plot(np.sort(probas[:, i]), c='grey', alpha=0.5)\n",
    "        axs[1].plot(np.sort(ground_truth['proba']), np.sort(probas[:, i]), c='grey', alpha=0.5)\n",
    "    if probas_alt is not None:\n",
    "        for i in range(probas_alt.shape[1]):\n",
    "            axs[0].plot(np.sort(probas_alt[:, i]), c=COLORS[2], alpha=0.5)\n",
    "            axs[1].plot(np.sort(ground_truth['proba']), np.sort(probas_alt[:, i]), c=COLORS[2], alpha=0.5)\n",
    "            \n",
    "    axs[0].plot(np.sort(ground_truth['proba']), c='red', ls='--', lw=2, zorder=10, label='True model')\n",
    "    axs[0].set_title('Probabilities -- model draws', fontsize=18)\n",
    "    axs[0].set_ylabel('proba', fontsize=18)\n",
    "    axs[0].set_xlabel('sorted observations', fontsize=18)\n",
    "    axs[0].tick_params(labelsize=16)\n",
    "    axs[0].legend(fontsize=18)\n",
    "    axs[1].plot(ground_truth['proba'], ground_truth['proba'], c='red', ls='--', lw=2, zorder=10, label='True model')\n",
    "    axs[1].set_title('model draws -- Q-Q ', fontsize=18)\n",
    "    axs[1].set_ylabel('proba -- ground truth', fontsize=18)\n",
    "    axs[1].set_xlabel('proba -- draws', fontsize=18)\n",
    "    axs[1].tick_params(labelsize=16)\n",
    "    axs[1].legend(fontsize=18)\n",
    "    \n",
    "    if fig is not None:\n",
    "        fig.tight_layout()\n",
    "        return fig, axs\n",
    "    return axs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d37953",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Metric Uncertainty\n",
    "\n",
    "## Ralph Urlus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edcd80d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What is model metric uncertainty?\n",
    "* Who has ever created a credible or confidence interval on your metrics?\n",
    "* Did you use cross-validation?\n",
    "* Did you have enough statistics to be confident in your CI?\n",
    "* Did you have an unbiased CI?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c26ed6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Model performance is a stochastic and depends on multiple sources of uncertainty\n",
    "\n",
    "We have well defined uncertainties on, most, statistical models why not on ML models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3bc5cb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The setting\n",
    "\n",
    "* Binary classification problem\n",
    "\n",
    "* Non-symmetrical costs for errors\n",
    "\n",
    "* Utility function over sensitivity (recall on the positive class) and specificity (recall on the negative class)\n",
    "\n",
    "* The utility function can be optimized for any model that outputs a probability using the classification threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39bd362",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problem statement\n",
    "\n",
    "Determine the optimal classification threshold that maximises the utility function over a pair of classification metrics considering their simultaneous uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8babab0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Let introduce a bit of formalism\n",
    "\n",
    "<sub><sup>I am sorry Fari</sup></sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abadca01",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Assume we have a classification problem with feature set $X \\subset \\mathbb{R}^{N \\mathrm{x} K}$ and labels $y = \\{y_{i} \\in \\{0, 1\\} \\mid 1 \\leq  i \\leq N\\}$.\n",
    "\n",
    "Let $T_{m} \\subset X$ be the train set and $Z_{m} \\subset X$ be the test set for run $ m \\in \\mathbb{M};~\\mathbb{M} = \\{1, \\ldots, M\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6883cd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Additionally let $T_{m} \\cap Z_{m} = \\emptyset~\\forall~m \\in \\mathbb{M}$ and \n",
    "\n",
    "$T_{i} \\cap Z_{j} \\not\\equiv \\emptyset~\\forall~i, j \\in \\mathbb{M}$\n",
    "\n",
    "where $a \\not\\equiv b$ denotes $a$ _is not necessarily equal to_ $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526edca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let $f_{m}:\\mathbf{x} \\to [0, 1]$ represent one of the $M$ model instances trained on $T_{m}$ with hyper-parameters $\\Theta_{m}$ and evaluated on $Z_{m}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196e0667",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Assume that $f$ is not deterministic given the same training data\n",
    "\n",
    "$f_{i}(T_{m}, \\Theta_{m}) \\not\\equiv f_{j}(T_{m}, \\Theta_{m})~\\forall~i, j \\in \\mathbb{M}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2758de",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Assume that not all observations are equivalently easy to predict\n",
    "\n",
    "$\\exists~i, j \\in N~|~i \\neq j \\text{ s.t. } P\\left(y_{i} = f_{m}(X_{i})\\right) > P\\left(y_{j} = f_{m}(X_{j})\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0457f8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We observe an estimate of the population metric $\\phi$:\n",
    "\\begin{equation*}\n",
    "    \\hat{\\phi} = \\phi + \\epsilon = \\phi + \\epsilon_{X} + \\epsilon_{f} = \\phi + \\epsilon_{T} + \\epsilon_{Z} + \\epsilon_{f}\n",
    "\\end{equation*}\n",
    "where $\\epsilon_{X}$ represents the error induced by the data sample, $\\epsilon_{f}$ the error due to non-deterministic behaviour during training and $\\epsilon_{T},~\\epsilon_{Z}$ are subcomponents of the data driven uncertainty in the form of the training and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4a4d75",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Uncertainties\n",
    "\n",
    "What uncertainties did we just include?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5852d0e9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ilan's list\n",
    "\n",
    "1. Sampling variation\n",
    "2. Measurement noise\n",
    "3. Model misspecification\n",
    "4. Overt overftting\n",
    "5. Covert overfitting\n",
    "6. Data leakage\n",
    "7. Pseudo-random number generation\n",
    "8. Dataset shift\n",
    "9. Optimisation ambiguities\n",
    "10. Identifiability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3e09db",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. Sampling variation -- Yes\n",
    "2. Measurement noise -- Yes\n",
    "3. Model misspecification -- No\n",
    "4. Overt overfitting -- Partially\n",
    "5. Covert overfitting -- No\n",
    "6. Data leakage -- Partially\n",
    "7. Pseudo-random number generation -- Partially\n",
    "8. Dataset shift -- Partially\n",
    "9. Optimisation ambiguities -- Partially\n",
    "10. Identifiability -- Yes\n",
    "\n",
    "Let's assume we don't screw up to often, we exclude mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27546d78",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### My list\n",
    "\n",
    "\n",
    "1. Assume that not all observations are equivalently easy to predict\n",
    "    * Sampling variation\n",
    "    * Overt overfitting\n",
    "    * Dataset shift\n",
    "2. Assume that $f$ is not deterministic given the same training data\n",
    "    * Overt overfitting\n",
    "    * Optimisation ambiguities\n",
    "    * Identifiability\n",
    "3. There can be overlap between the test and training sets between runs\n",
    "    * Data leakage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c81566",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### How do these uncertainties manifest themselves?\n",
    "\n",
    "In practise these uncertainties do not clearly distinguish themselves\n",
    "\n",
    "An analytical description of these joint uncertainties is unlikely to exist.\n",
    "\n",
    "For example, a Gaussian error on $\\theta = \\alpha + \\beta_{0} * X_{0} + ...$ before the logistic function in Logistic Regression results in Logit-normal distributed error in the probability space which does not have any moments that can be described analytically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30261c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simulation it is...\n",
    "\n",
    "So how do simulate all these uncertainties involved?\n",
    "\n",
    "What if we can simulate classifiers where we can turn on and off various sources of uncertainty? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d21d6f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### ModelGenerator\n",
    "\n",
    "We developed a model generator that can incorporate and isolate these sources:\n",
    "\n",
    "1. Sampling uncertainty\n",
    "\n",
    "    * number of data points\n",
    "    * split between train test (sample noise)\n",
    "    * class imbalance\n",
    "    * sub-class imbalance (cluster imbalances)\n",
    "   \n",
    "2. Measurement noise\n",
    "    \n",
    "    * noise over X (cluster noise)\n",
    "    * label noise (label noise)\n",
    "    \n",
    "3. Non deterministic training (model noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0604ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The generator is an extension of sklearn's `make_classification`.\n",
    "\n",
    "Generate `n_clusters_per_class` positioned on the vertices off a hypercube and assign a class label.\n",
    "For binary classification and 2 clusters per class we have 4 clusters.\n",
    "\n",
    "1. For each cluster generate a hypersphere of dimension `n_features` from standard normals.\n",
    "2. Generate a random covariance matrix per cluster over the features\n",
    "3. Shift the hyperspheres to the centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35aa07e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Ground truth\n",
    "\n",
    "We need a deterministic base model:\n",
    "\n",
    "1. Sample 250K samples from X and y that are noise free\n",
    "2. Fit Logistic regression on X, y\n",
    "3. Store coefficients\n",
    "\n",
    "This model should be, largely, free of noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f2ffb3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefcd0a2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "generator = ModelGenerator(random_state=12345)\n",
    "fit = generator.fit()\n",
    "train_mask, labels, probas, X, models, ground_truth = fit.transform(\n",
    "    n_models=100,\n",
    "    n_samples=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832a1430",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c799917f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c708e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "probas[:5, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a9bf7f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_probas(probas, ground_truth) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b53795",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Without the uncertainties\n",
    "\n",
    "What does it look like if we disable all uncertainties in the generator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7cbb5a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "generator = ModelGenerator(random_state=12345)\n",
    "fit = generator.fit()\n",
    "train_mask, labels, probas, X, models, ground_truth = fit.transform(\n",
    "    n_models=100,\n",
    "    n_samples=5000,\n",
    "    enable_cluster_imbalances=False,\n",
    "    enable_cluster_noise=False,\n",
    "    enable_sample_noise=False,\n",
    "    enable_label_noise=False,\n",
    "    enable_model_noise=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225e499",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_probas(probas, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced6ee6d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sample noise \n",
    "\n",
    "Sample noise here is defined as the effects due having sampled a different train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5f593",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "generator = ModelGenerator(random_state=12345)\n",
    "fit = generator.fit()\n",
    "train_mask, labels, probas, X, models, ground_truth = fit.transform(\n",
    "    n_models=100,\n",
    "    n_samples=5000,\n",
    "    enable_sample_noise=True,\n",
    "    enable_cluster_imbalances=False,\n",
    "    enable_cluster_noise=False,\n",
    "    enable_label_noise=False,\n",
    "    enable_model_noise=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e2a72",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_probas(probas, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2535edd5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Cluster imbalances\n",
    "\n",
    "Cluster imbalances are introduced by creating clusters that are of uneven size based on sample from a Dirichlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae79645",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "generator = ModelGenerator(random_state=12345)\n",
    "fit = generator.fit()\n",
    "train_mask, labels, probas, X, models, ground_truth = fit.transform(\n",
    "    n_models=100,\n",
    "    n_samples=5000,\n",
    "    alpha_weights=10,\n",
    "    enable_sample_noise=False,\n",
    "    enable_cluster_imbalances=True,\n",
    "    enable_cluster_noise=False,\n",
    "    enable_label_noise=False,\n",
    "    enable_model_noise=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc582752",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_probas(probas, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac01f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Cluster noise\n",
    "\n",
    "Scale and shift clusters of X to simulate certain subclasses/observations that are harder to predict than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db65e1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "generator = ModelGenerator(random_state=12345)\n",
    "fit = generator.fit()\n",
    "train_mask, labels, probas, X, models, ground_truth = fit.transform(\n",
    "    n_models=100,\n",
    "    n_samples=5000,\n",
    "    alpha_weights=10,\n",
    "    enable_sample_noise=False,\n",
    "    enable_cluster_imbalances=False,\n",
    "    enable_cluster_noise=True,\n",
    "    enable_label_noise=False,\n",
    "    enable_model_noise=False,\n",
    ")\n",
    "\n",
    "probas_alt = probas.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c3e77",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_probas(probas, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0142a986",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Cluster noise and imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57634d3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "generator = ModelGenerator(random_state=12345)\n",
    "fit = generator.fit()\n",
    "train_mask, labels, probas, X, models, ground_truth = fit.transform(\n",
    "    n_models=100,\n",
    "    n_samples=5000,\n",
    "    alpha_weights=10,\n",
    "    enable_sample_noise=False,\n",
    "    enable_cluster_imbalances=True,\n",
    "    enable_cluster_noise=True,\n",
    "    enable_label_noise=False,\n",
    "    enable_model_noise=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73777b9f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_probas(probas, ground_truth, probas_alt=probas_alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7949deb3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Label Noise\n",
    "\n",
    "The probability of a label being flipped is 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2628bb7f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "generator = ModelGenerator(random_state=12345)\n",
    "fit = generator.fit()\n",
    "train_mask, labels, probas, X, models, ground_truth = fit.transform(\n",
    "    n_models=100,\n",
    "    n_samples=5000,\n",
    "    alpha_weights=10,\n",
    "    enable_sample_noise=False,\n",
    "    enable_cluster_imbalances=False,\n",
    "    enable_cluster_noise=False,\n",
    "    enable_label_noise=True,\n",
    "    enable_model_noise=False,\n",
    ")\n",
    "\n",
    "probas_alt = probas.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05553bdd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_probas(probas, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e76028f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "10% label flip probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f8e63a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "generator = ModelGenerator(label_flip=0.1, random_state=12345)\n",
    "fit = generator.fit()\n",
    "train_mask, labels, probas, X, models, ground_truth = fit.transform(\n",
    "    n_models=100,\n",
    "    n_samples=5000,\n",
    "    alpha_weights=10,\n",
    "    enable_sample_noise=False,\n",
    "    enable_cluster_imbalances=False,\n",
    "    enable_cluster_noise=False,\n",
    "    enable_label_noise=True,\n",
    "    enable_model_noise=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce95a4d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_probas(probas, ground_truth, probas_alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729e4ff2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Model noise\n",
    "\n",
    "Rotation and shift to the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f74ff",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "generator = ModelGenerator(random_state=12345)\n",
    "fit = generator.fit()\n",
    "train_mask, labels, probas, X, models, ground_truth = fit.transform(\n",
    "    n_models=100,\n",
    "    n_samples=5000,\n",
    "    alpha_weights=10,\n",
    "    enable_sample_noise=False,\n",
    "    enable_cluster_imbalances=False,\n",
    "    enable_cluster_noise=False,\n",
    "    enable_label_noise=False,\n",
    "    enable_model_noise=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbf6c5d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_probas(probas, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06edc18f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Model noise -- no rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871490f0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "generator = ModelGenerator(\n",
    "    model_rotation=0.0,\n",
    "    random_state=12345\n",
    ")\n",
    "fit = generator.fit()\n",
    "train_mask, labels, probas, X, models, ground_truth = fit.transform(\n",
    "    n_models=100,\n",
    "    n_samples=5000,\n",
    "    alpha_weights=10,\n",
    "    enable_sample_noise=False,\n",
    "    enable_cluster_imbalances=False,\n",
    "    enable_cluster_noise=False,\n",
    "    enable_label_noise=False,\n",
    "    enable_model_noise=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf3ff4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_probas(probas, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4fd9d8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Model noise -- no shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc9c3d5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "generator = ModelGenerator(\n",
    "    model_shift=0.0,\n",
    "    random_state=12345\n",
    ")\n",
    "fit = generator.fit()\n",
    "train_mask, labels, probas, X, models, ground_truth = fit.transform(\n",
    "    n_models=100,\n",
    "    n_samples=5000,\n",
    "    alpha_weights=10,\n",
    "    enable_sample_noise=False,\n",
    "    enable_cluster_imbalances=False,\n",
    "    enable_cluster_noise=False,\n",
    "    enable_label_noise=False,\n",
    "    enable_model_noise=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa4e19",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_probas(probas, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bbadf8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Data driven uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be76d3d0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "generator = ModelGenerator(random_state=12345)\n",
    "fit = generator.fit()\n",
    "train_mask, labels, probas, X, models, ground_truth = fit.transform(\n",
    "    n_models=100,\n",
    "    n_samples=5000,\n",
    "    alpha_weights=10,\n",
    "    enable_sample_noise=True,\n",
    "    enable_cluster_imbalances=True,\n",
    "    enable_cluster_noise=True,\n",
    "    enable_label_noise=False,\n",
    "    enable_model_noise=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9cf600",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_probas(probas, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483657df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### All sources uncertainty combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40e038d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "generator = ModelGenerator(random_state=12345)\n",
    "fit = generator.fit()\n",
    "train_mask, labels, probas, X, models, ground_truth = fit.transform(\n",
    "    n_models=100,\n",
    "    n_samples=5000,\n",
    "    alpha_weights=10,\n",
    "    enable_sample_noise=True,\n",
    "    enable_cluster_imbalances=True,\n",
    "    enable_cluster_noise=True,\n",
    "    enable_label_noise=True,\n",
    "    enable_model_noise=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef51c73",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_probas(probas, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa655d89",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f70c5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Experiment week\n",
    "\n",
    "We want to explore different modelling approaches, e.g.\n",
    "* Beta-Binomial\n",
    "* Dirichlet-Multinomial\n",
    "* Bootstrapping\n",
    "\n",
    "Model the Precision-Recall curve with a Gaussian Processes:\n",
    "* with uncertainty on X\n",
    "* with heterogeneous errors\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4c6efe",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Data science 'hobby project'\n",
    "\n",
    "We want to develop a package that becomes the, internal, standard for model evaluation.\n",
    "\n",
    "We would be happy if you joined the efforts.\n",
    "\n",
    "Thus far we have:\n",
    "* the draft simulation engine\n",
    "* fast confusion matrix & computation of binary classification metrics\n",
    "    * 0 - neg.precision aka Negative Predictive Value\n",
    "    * 1 - pos.precision aka Positive Predictive Value\n",
    "    * 2 - neg.recall aka True Negative Rate & Specificity\n",
    "    * 3 - pos.recall aka True Positive Rate aka Sensitivity\n",
    "    * 4 - neg.f1 score\n",
    "    * 5 - pos.f1 score\n",
    "    * 6 - False Positive Rate\n",
    "    * 7 - False Negative Rate\n",
    "    * 8 - Accuracy\n",
    "    * 9 - MCC\n",
    "    \n",
    "    * Plus we are 700 times faster than sklearn while computing 4 metrics more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d86c0e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Get a master student\n",
    "\n",
    "There relatively little literature on the topic.\n",
    "\n",
    "Most literature focusses on distinguishing the better model from a small set.\n",
    "\n",
    "But how do we get well defined uncertainties in the setting we discussed above?\n",
    "\n",
    "If we can come up with a good approach we try to publish it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e20bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Up next:\n",
    "\n",
    "## A Beta-Binomial model for a confusion matrix\n",
    "\n",
    "### Ilan Fridman Rojas"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
