{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CC\"] = \"/opt/rh/devtoolset-10/root/usr/bin/gcc\"\n",
    "os.environ[\"CXX\"] = \"/opt/rh/devtoolset-10/root/usr/bin/g++\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will showcase the performance of a single run of test set - Bootstrap, k-fold cross validation, and a Dirichlet-Multinomial model for estimating the distribution of the confusion matrix in binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import levene\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from mmur.simulators import LAlgorithm\n",
    "from mmur.generators import BlobGenerator\n",
    "from mmur.methods import single_run as sr\n",
    "from mmur import DirichletMultinomialConfusionMatrix\n",
    "from mmur import BetaBinomialConfusionMatrix\n",
    "import mmu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, consider only the randomness due to test set sampling. We keep a fixed train set, and attempt to predict how well a classifier predicts on new test data (from the same data distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# TODO: replace with mmu function, binary_metrics\n",
    "\n",
=======
>>>>>>> ignore
    "def cms_to_precision(cms):\n",
    "    \"\"\"\n",
    "        Computes the precisions based on a list of confusion matrices\n",
    "\n",
    "        Parameters\n",
    "        cms : list\n",
    "            List of (2 by 2) confusion matrices, where each confusion matrix is a list with two sublists\n",
    "            of length 2, containing the counts. [[true negatives,false positives],[false negatives,true positives]]\n",
    "\n",
    "        Returns\n",
    "        TP/(TP+FP) : ndarray\n",
    "            1D numpy array of precisions\n",
    "        \"\"\"\n",
    "\n",
    "    # cms_array = np.array(cms)\n",
    "    TP = cms[:, 3]\n",
    "    FP = cms[:, 1]\n",
    "    return TP/(TP+FP)\n",
    "\n",
    "def cms_to_recall(cms):\n",
    "    \"\"\"\n",
    "    Computes the recalls based on a list of confusion matrices\n",
    "\n",
    "    Parameters\n",
    "    cms : list\n",
    "        List of(2 by 2) confusion matrices, where each confusion matrix is a list with two sublists\n",
    "        of length 2, containing the counts. [[true negatives, false positives], [false negatives, true positives]]\n",
    "\n",
    "    Returns\n",
    "    TP/(TP+FN) : ndarray\n",
    "        Vector of recalls\n",
    "    \"\"\"\n",
    "    cms_array = np.array(cms)\n",
    "    TP = cms_array[:, 3]\n",
    "    FN = cms_array[:, 2]\n",
    "    return TP/(TP+FN)\n",
    "\n",
    "def run_sr_methods(X,y,model_class,train_size,model_kwargs = {},n_bs_draws = 1, n_cv_splits = 5,random_state=None):\n",
    "    \"\"\"\n",
    "        Use various methods to estimate the distribution of the confusion matrix for a fixed train set. Includes bootstrapping the test set, k-fold cross-validation \n",
    "        and a Dirichlet-Multinomial Bayesian approach (Caelen 2017).\n",
    "\n",
    "        Parameters\n",
    "        X : np.ndarray[n,k]\n",
    "            Input features\n",
    "\n",
    "        y : np.ndarray[n]\n",
    "            Labels, 0 or 1\n",
    "\n",
    "        model_class : ...\n",
    "            model to be fitted and used to predict test labels\n",
    "        \n",
    "        train_size : float\n",
    "            Fraction of observations to use for training, rest is used for testing. Determined by order; first `train_size` portion of observations are used for training.\n",
    "\n",
    "        model_kwargs : dict\n",
    "            Contains the arguments to intialize the model\n",
    "\n",
    "        n_bs_draws : int, default=1\n",
    "            number of bootstrap samples to draw\n",
    "        \n",
    "        n_cv_splits : int, default=5\n",
    "            number of splits (k) used for k-fold cross-validation\n",
    "\n",
    "        random_state : int, default=None\n",
    "            State that determines the bootstrap draws, cross-validation splits, posterior fit for the Bayesian model, and potentially non-deterministic model training\n",
    "    \"\"\"\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    model = model_class(**model_kwargs).fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm_test = confusion_matrix(y_test,y_pred).flatten()\n",
    "\n",
    "    cm_bs = sr.bstrp_cm(cm_test, n_bs_draws, random_state)\n",
    "    cm_cv = sr.kfold_cm(X, y, model_class, model_kwargs, n_cv_splits, random_state)\n",
    "    Dir_mn  = DirichletMultinomialConfusionMatrix(random_state)\n",
    "    cm_DM = Dir_mn.fit_predict(cm_test)\n",
    "\n",
    "    return cm_test, cm_bs, cm_cv, cm_DM"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 17,
>>>>>>> ignore
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# generator = BlobGenerator(data_size,int(test_size * n_sets),weights=[0.8,0.2])\n",
    "# X,y = generator.make_classification(random_state)\n",
    "X = np.arange(100).reshape((50,2))\n",
    "y = np.arange(1000)\n",
    "y.reshape(100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(train_size=5000,test_size=1000,n_sets=1e4,weights=[0.8,0.2],random_state=None):\n",
    "    data_size=train_size+test_size\n",
    "    \n",
    "    generator = BlobGenerator(data_size,int(test_size * n_sets),weights=[0.8,0.2])\n",
    "    X,y = generator.make_classification(random_state)\n",
    "    \n",
    "    X_in, y_in = X[:data_size], y[:data_size]\n",
    "    X_out, y_out = X[data_size:].reshape((-1, test_size, 2)), y[data_size:].reshape((-1, test_size)) #TODO: change to (N,K) dimensional arrays\n",
    "\n",
    "    X_train, X_test = X_in[:train_size], X_in[train_size:data_size]\n",
    "    y_train, y_test = y_in[:train_size], y_in[train_size:data_size]\n",
    "    return X_train,y_train,X_test,y_test,X_out,y_out\n",
    "\n",
    "X_train,y_train,X_test,y_test,X_out,y_out = gen_data()\n",
    "\n",
    "# Generate data from Gaussian blobs\n",
    "# generator = BlobGenerator(6000,int(1000 * 1e4),weights=[0.8,0.2])\n",
    "# X,y = generator.make_classification(1)\n",
    "\n",
    "# Known data sample, used for train + test\n",
    "# X_in, y_in = X[:6000], y[:6000]\n",
    "\n",
    "# Unknown data samples, used to evaluate true model performance\n",
    "# X_out, y_out = X[6000:].reshape((-1, 1000, 2)), y[6000:].reshape((-1, 1000))\n",
    "\n",
    "# Train/test split\n",
    "# X_train, X_test = X_in[:5000], X_in[5000:6000]\n",
    "# y_train, y_test = y_in[:5000], y_in[5000:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_cm(model_class,X_train,y_train,X_out,y_out,model_kwargs={},tau=0.5):\n",
    "\n",
    "    # fit the model to the fixed train set\n",
    "    model = model_class(**model_kwargs).fit(X_train,y_train)\n",
    "\n",
    "    #\n",
    "    y_pred = model.predict(X_out.reshape((-1,2))).reshape((1000,-1))\n",
    "    \n",
    "    # cm_true = np.zeros((y_pred.shape[0],4),dtype=int)\n",
    "    # for i,(true,predicted) in enumerate(zip(y_out,y_pred)):\n",
    "    #     cm_true[i,:] = confusion_matrix(true,predicted).flatten()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = LogisticRegression\n",
    "model_kwargs = {'penalty':'none'}\n",
    "model = model_class(**model_kwargs).fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_out.reshape((-1,2))).reshape((-1,1000))\n",
    "\n",
    "cm, metrics = mmu.binary_metrics_runs(\n",
    "    y, yhat=y_pred, obs_axis=1, fill=0.0, return_df=False\n",
    ") #TODO: check this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the true confusion matrix distribution\n",
    "\n",
    "model_class = LogisticRegression\n",
    "model_kwargs = {'penalty':'none'}\n",
    "model = model_class(**model_kwargs).fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_out.reshape((-1,2))).reshape((-1,1000))\n",
    "cm_true = np.zeros((y_pred.shape[0],4),dtype=int)\n",
    "for i,(true,predicted) in enumerate(zip(y_out,y_pred)):\n",
    "    cm_true[i,:] = confusion_matrix(true,predicted).flatten()\n",
    "\n",
    "precs_true = cms_to_precision(cm_true)\n",
    "recs_true = cms_to_recall(cm_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_iv(values,qrange = 0.95):\n",
    "    \"\"\"produces an interval based on a median-centered quantile range\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    values : _type_\n",
    "        _description_\n",
    "    qrange : float, optional\n",
    "        _description_, by default 0.95\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    upper = np.quantile(values,(1-qrange)/2)\n",
    "    lower = np.quantile(values,1-(1-qrange)/2)\n",
    "    return upper,lower\n",
    "\n",
    "\n",
    "def frac_in_interval(values,interval):\n",
    "    return np.mean((interval[0]<values) & (values<interval[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test, cm_bs, cm_cv, cm_DM = run_sr_methods(X_in,y_in,LogisticRegression,5000,{'penalty':'none'},1000,6,1)\n",
    "prec_test, precs_bs, precs_cv, precs_dm = cms_to_precision(cm_test.reshape(-1,4))[0], cms_to_precision(cm_bs),cms_to_precision(cm_cv), cms_to_precision(cm_DM)\n",
    "rec_test, recs_bs, recs_cv, recs_dm = cms_to_recall(cm_test.reshape(-1,4))[0], cms_to_recall(cm_bs),cms_to_recall(cm_cv), cms_to_recall(cm_DM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of the estimated predicton intervals of the precision, compared to the true out-of-sample metric distribution\n",
    "\n",
    "sns.displot(precs_true, kind='kde')\n",
    "\n",
    "plt.vlines(prec_test, 0, 12, label = 'Point-estimate')\n",
    "plt.vlines(quantile_iv(precs_bs), 0, 12, colors = 'blue', linestyles='dashed',label='Bootstrap test set')\n",
    "plt.vlines(quantile_iv(precs_cv), 0, 12, colors='green', linestyles='dashed',label='6-fold CV')\n",
    "plt.vlines(quantile_iv(precs_dm), 0, 12, colors='purple', linestyles='dashed',label='Dirichlet-Multinomial')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "recs_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
=======
>>>>>>> ignore
    "# Plots of the estimated predicton intervals of the recall, compared to the true out-of-sample metric distribution\n",
    "\n",
    "sns.displot(recs_true, kind='kde')\n",
    "\n",
    "plt.vlines(rec_test, 0, 12, label = 'Point-estimate')\n",
    "plt.vlines(quantile_iv(recs_bs), 0, 12, colors = 'blue', linestyles='dashed',label='Bootstrap test set')\n",
    "plt.vlines(quantile_iv(recs_cv), 0, 12, colors='green', linestyles='dashed',label='6-fold CV')\n",
    "plt.vlines(quantile_iv(recs_dm), 0, 12, colors='purple', linestyles='dashed',label='Dirichlet-Multinomial')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_interval(est_values, true_values, qrange=0.95):\n",
    "    lower,upper=quantile_iv(est_values,qrange=qrange)\n",
    "    interval = (lower,upper)\n",
    "    coverage = frac_in_interval(true_values,interval)\n",
    "    width = interval[1]-interval[0]\n",
    "    return [lower,upper,width,coverage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of precision prediction interval\n",
    "\n",
    "prec_iv_scores = []\n",
    "for precs_est in [precs_bs,precs_cv,precs_dm]:\n",
    "    prec_iv_scores.append(score_interval(precs_est,precs_true))\n",
    "pd.DataFrame(prec_iv_scores,index = ['Bootstrap','6-fold CV','Dir-Mn'],columns = ['lower','upper','width','coverage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of recall prediction interval\n",
    "\n",
    "rec_iv_scores = []\n",
    "for recs_est in [recs_bs,recs_cv,recs_dm]:\n",
    "    rec_iv_scores.append(score_interval(recs_est,recs_true))\n",
    "pd.DataFrame(rec_iv_scores,index = ['Bootstrap','6-fold CV','Dir-Mn'],columns = ['lower','upper','width','coverage'])"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: joint uncertainty interval of the precision and recall for btstrp and k-fold cv"
   ]
=======
>>>>>>> ignore
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50e2ea73d98f6ee2d543936d9795e87546ceaa579e11054f6af1573a6cde0e6b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.8.11"
=======
   "version": "3.10.4"
>>>>>>> ignore
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
