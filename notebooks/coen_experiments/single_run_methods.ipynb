{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will showcase the performance of a single run of test set - Bootstrap, k-fold cross validation, and a Dirichlet-Multinomial model for estimating the distribution of the confusion matrix in binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import levene\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from mmur.simulators import LAlgorithm\n",
    "from mmur.generators import BlobGenerator\n",
    "from mmur.methods import single_run as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, consider only the randomness due to test set sampling. We keep a fixed train set, and attempt to predict how well a classifier predicts on new test data (from the same data distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cms_to_precision(cms):\n",
    "    \"\"\"\n",
    "        Computes the precisions based on a list of confusion matrices\n",
    "\n",
    "        Parameters\n",
    "        cms : list\n",
    "            List of (2 by 2) confusion matrices, where each confusion matrix is a list with two sublists\n",
    "            of length 2, containing the counts. [[true negatives,false positives],[false negatives,true positives]]\n",
    "\n",
    "        Returns\n",
    "        TP/(TP+FP) : ndarray\n",
    "            1D numpy array of precisions\n",
    "        \"\"\"\n",
    "\n",
    "    # cms_array = np.array(cms)\n",
    "    TP = cms[:, 3]\n",
    "    FP = cms[:, 1]\n",
    "    return TP/(TP+FP)\n",
    "\n",
    "def run_sr_methods(X,y,model_class,train_size,model_kwargs = {},n_bs_draws = 1, n_cv_splits = 5,random_state=None):\n",
    "\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    model = model_class(**model_kwargs).fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm_test = confusion_matrix(y_test,y_pred).flatten()\n",
    "\n",
    "    cm_bs = sr.bstrp_cm(cm_test, n_bs_draws, random_state)\n",
    "    cm_cv = sr.kfold_cm(X, y, model_class, model_kwargs, n_cv_splits, random_state)\n",
    "\n",
    "    return cm_test, cm_bs, cm_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data from Gaussian blobs\n",
    "generator = BlobGenerator(6000,int(1000 * 1e4),weights=[0.8,0.2])\n",
    "X,y = generator.make_classification(1)\n",
    "\n",
    "# Known data sample, used for train + test\n",
    "X_in, y_in = X[:6000], y[:6000]\n",
    "\n",
    "# Unknown data samples, used to evaluate true model performance\n",
    "X_out, y_out = X[6000:].reshape((-1, 1000, 2)), y[6000:].reshape((-1, 1000))\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test = X_in[:5000], X_in[5000:6000]\n",
    "y_train, y_test = y_in[:5000], y_in[5000:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = LogisticRegression\n",
    "model_kwargs = {'penalty':'none'}\n",
    "model = model_class(**model_kwargs).fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_out.reshape((-1,2))).reshape((-1,1000))\n",
    "cm_true = np.zeros((y_pred.shape[0],4),dtype=int)\n",
    "for i,(true,predicted) in enumerate(zip(y_out,y_pred)):\n",
    "    cm_true[i,:] = confusion_matrix(true,predicted).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_iv(values,qrange = 0.95):\n",
    "    \"\"\"produces an interval based on a median-centered quantile range\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    values : _type_\n",
    "        _description_\n",
    "    qrange : float, optional\n",
    "        _description_, by default 0.95\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    upper = np.quantile(values,(1-qrange)/2)\n",
    "    lower = np.quantile(values,1-(1-qrange)/2)\n",
    "    return upper,lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test, cm_bs, cm_cv = run_sr_methods(X_in,y_in,LogisticRegression,5000,{'penalty':'none'},1000,6,1)\n",
    "prec_test, precs_bs,precs_cv = cms_to_precision(cm_test.reshape(-1,4))[0], cms_to_precision(cm_bs),cms_to_precision(cm_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precs_true = cms_to_precision(cm_true)\n",
    "\n",
    "sns.displot(precs_true, kind='kde')\n",
    "\n",
    "\n",
    "plt.vlines(prec_test, 0, 12, label = 'Point-estimate')\n",
    "plt.vlines(quantile_iv(precs_bs), 0, 12, colors = 'red', linestyles='dashed',label='Bootstrap test set')\n",
    "plt.vlines(quantile_iv(precs_cv), 0, 12, colors='green', linestyles='dashed',label='6-fold CV')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval=quantile_iv(precs_bs)\n",
    "interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_iv(cms_to_precision(cm_cv), 0.95)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50e2ea73d98f6ee2d543936d9795e87546ceaa579e11054f6af1573a6cde0e6b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
