{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
=======
    "# import os\n",
    "\n",
    "# os.environ[\"CC\"] = \"/opt/rh/devtoolset-10/root/usr/bin/gcc\"\n",
    "# os.environ[\"CXX\"] = \"/opt/rh/devtoolset-10/root/usr/bin/g++\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> NTB: include Dir-Mn method, create result df
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will showcase the performance of a single run of test set - Bootstrap, k-fold cross validation, and a Dirichlet-Multinomial model for estimating the distribution of the confusion matrix in binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import levene\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from mmur.simulators import LAlgorithm\n",
    "from mmur.generators import BlobGenerator\n",
    "from mmur.methods import single_run as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, consider only the randomness due to test set sampling. We keep a fixed train set, and attempt to predict how well a classifier predicts on new test data (from the same data distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cms_to_precision(cms):\n",
    "    \"\"\"\n",
    "        Computes the precisions based on a list of confusion matrices\n",
    "\n",
    "        Parameters\n",
    "        cms : list\n",
    "            List of (2 by 2) confusion matrices, where each confusion matrix is a list with two sublists\n",
    "            of length 2, containing the counts. [[true negatives,false positives],[false negatives,true positives]]\n",
    "\n",
    "        Returns\n",
    "        TP/(TP+FP) : ndarray\n",
    "            1D numpy array of precisions\n",
    "        \"\"\"\n",
    "\n",
    "    # cms_array = np.array(cms)\n",
    "    TP = cms[:, 3]\n",
    "    FP = cms[:, 1]\n",
    "    return TP/(TP+FP)\n",
    "\n",
    "def run_sr_methods(X,y,model_class,train_size,model_kwargs = {},n_bs_draws = 1, n_cv_splits = 5,random_state=None):\n",
    "    \"\"\"\n",
    "        Use various methods to estimate the distribution of the confusion matrix for a fixed train set. Includes bootstrapping the test set, k-fold cross-validation \n",
    "        and a Dirichlet-Multinomial Bayesian approach (Caelen 2017).\n",
    "\n",
    "        Parameters\n",
    "        X : np.ndarray[n,k]\n",
    "            Input features\n",
    "\n",
    "        y : np.ndarray[n]\n",
    "            Labels, 0 or 1\n",
    "\n",
    "        model_class : ...\n",
    "            model to be fitted and used to predict test labels\n",
    "        \n",
    "        train_size : float\n",
    "            Fraction of observations to use for training, rest is used for testing. Determined by order; first `train_size` portion of observations are used for training.\n",
    "\n",
    "        model_kwargs : dict\n",
    "            Contains the arguments to intialize the model\n",
    "\n",
    "        n_bs_draws : int, default=1\n",
    "            number of bootstrap samples to draw\n",
    "        \n",
    "        n_cv_splits : int, default=5\n",
    "            number of splits (k) used for k-fold cross-validation\n",
    "\n",
    "        random_state : int, default=None\n",
    "            State that determines the bootstrap draws, cross-validation splits, posterior fit for the Bayesian model, and potentially non-deterministic model training\n",
    "    \"\"\"\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    model = model_class(**model_kwargs).fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm_test = confusion_matrix(y_test,y_pred).flatten()\n",
    "\n",
    "    cm_bs = sr.bstrp_cm(cm_test, n_bs_draws, random_state)\n",
    "    cm_cv = sr.kfold_cm(X, y, model_class, model_kwargs, n_cv_splits, random_state)\n",
    "\n",
    "    return cm_test, cm_bs, cm_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data from Gaussian blobs\n",
    "generator = BlobGenerator(6000,int(1000 * 1e4),weights=[0.8,0.2])\n",
    "X,y = generator.make_classification(1)\n",
    "\n",
    "# Known data sample, used for train + test\n",
    "X_in, y_in = X[:6000], y[:6000]\n",
    "\n",
    "# Unknown data samples, used to evaluate true model performance\n",
    "X_out, y_out = X[6000:].reshape((-1, 1000, 2)), y[6000:].reshape((-1, 1000))\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test = X_in[:5000], X_in[5000:6000]\n",
    "y_train, y_test = y_in[:5000], y_in[5000:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the true confusion matrix distribution\n",
    "\n",
    "model_class = LogisticRegression\n",
    "model_kwargs = {'penalty':'none'}\n",
    "model = model_class(**model_kwargs).fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_out.reshape((-1,2))).reshape((-1,1000))\n",
    "cm_true = np.zeros((y_pred.shape[0],4),dtype=int)\n",
    "for i,(true,predicted) in enumerate(zip(y_out,y_pred)):\n",
    "    cm_true[i,:] = confusion_matrix(true,predicted).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_iv(values,qrange = 0.95):\n",
    "    \"\"\"produces an interval based on a median-centered quantile range\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    values : _type_\n",
    "        _description_\n",
    "    qrange : float, optional\n",
    "        _description_, by default 0.95\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    upper = np.quantile(values,(1-qrange)/2)\n",
    "    lower = np.quantile(values,1-(1-qrange)/2)\n",
    "    return upper,lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "cm_test, cm_bs, cm_cv = run_sr_methods(X_in,y_in,LogisticRegression,5000,{'penalty':'none'},1000,6,1)\n",
    "prec_test, precs_bs,precs_cv = cms_to_precision(cm_test.reshape(-1,4))[0], cms_to_precision(cm_bs),cms_to_precision(cm_cv)"
=======
    "cm_test, cm_bs, cm_cv, cm_DM = run_sr_methods(X_in,y_in,LogisticRegression,5000,{'penalty':'none'},1000,6,1)\n",
    "prec_test, precs_bs, precs_cv, precs_dm = cms_to_precision(cm_test.reshape(-1,4))[0], cms_to_precision(cm_bs),cms_to_precision(cm_cv), cms_to_precision(cm_DM)\n",
    "rec_test, recs_bs, recs_cv, recs_dm = cms_to_recall(cm_test.reshape(-1,4))[0], cms_to_recall(cm_bs),cms_to_recall(cm_cv), cms_to_recall(cm_DM)"
>>>>>>> NTB: include Dir-Mn method, create result df
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
=======
    "# Plots of the estimated predicton intervals, compared to the true out-of-sample metric distribution\n",
    "\n",
>>>>>>> NTB: include Dir-Mn method, create result df
    "precs_true = cms_to_precision(cm_true)\n",
    "\n",
    "sns.displot(precs_true, kind='kde')\n",
    "\n",
    "\n",
    "plt.vlines(prec_test, 0, 12, label = 'Point-estimate')\n",
<<<<<<< HEAD
    "plt.vlines(quantile_iv(precs_bs), 0, 12, colors = 'red', linestyles='dashed',label='Bootstrap test set')\n",
    "plt.vlines(quantile_iv(precs_cv), 0, 12, colors='green', linestyles='dashed',label='6-fold CV')\n",
=======
    "plt.vlines(quantile_iv(precs_bs), 0, 12, colors = 'blue', linestyles='dashed',label='Bootstrap test set')\n",
    "plt.vlines(quantile_iv(precs_cv), 0, 12, colors='green', linestyles='dashed',label='6-fold CV')\n",
    "plt.vlines(quantile_iv(precs_dm), 0, 12, colors='green', linestyles='dashed',label='6-fold CV')\n",
>>>>>>> NTB: include Dir-Mn method, create result df
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval=quantile_iv(precs_bs)\n",
    "interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "quantile_iv(cms_to_precision(cm_cv), 0.95)\n"
   ]
=======
    "# precision\n",
    "\n",
    "prec_iv_scores = []\n",
    "for precs_est in [precs_bs,precs_cv,precs_dm]:\n",
    "    prec_iv_scores.append(score_interval(precs_est,precs_true))\n",
    "pd.DataFrame(prec_iv_scores,index = ['Bootstrap','6-fold CV','Dir-Mn'],columns = ['lower','upper','width','coverage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "\n",
    "rec_iv_scores = []\n",
    "for recs_est in [recs_bs,recs_cv,recs_dm]:\n",
    "    rec_iv_scores.append(score_interval(recs_est,recs_true))\n",
    "pd.DataFrame(rec_iv_scores,index = ['Bootstrap','6-fold CV','Dir-Mn'],columns = ['lower','upper','width','coverage'])"
   ]
>>>>>>> NTB: include Dir-Mn method, create result df
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50e2ea73d98f6ee2d543936d9795e87546ceaa579e11054f6af1573a6cde0e6b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.9.5"
=======
   "version": "3.10.4"
>>>>>>> NTB: include Dir-Mn method, create result df
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
