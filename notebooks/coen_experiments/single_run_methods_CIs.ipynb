{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CC\"] = \"/opt/rh/devtoolset-10/root/usr/bin/gcc\"\n",
    "os.environ[\"CXX\"] = \"/opt/rh/devtoolset-10/root/usr/bin/g++\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will showcase the performance of a single run of test set - Bootstrap, k-fold cross validation, and a Dirichlet-Multinomial model for estimating the distribution of the confusion matrix in binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "import itertools as it\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import levene\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from mmur.simulators import LAlgorithm\n",
    "from mmur.generators import BlobGenerator\n",
    "from mmur.methods import single_run as sr\n",
    "from mmur import DirichletMultinomialConfusionMatrix\n",
    "from mmur import BetaBinomialConfusionMatrix\n",
    "import mmu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, consider only the randomness due to test set sampling. We keep a fixed train set, and attempt to predict how well a classifier predicts on new test data (from the same data distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(train_size=5000,test_size=1000,n_sets=1e4,weights=[0.8,0.2],random_state=None):\n",
    "    generator = BlobGenerator(train_size,int(test_size * n_sets),weights=weights)\n",
    "    X,y = generator.make_classification(random_state)\n",
    "\n",
    "    X_train, y_train = X[:train_size], y[:train_size]\n",
    "    X_out, y_out = X[train_size:], y[train_size:]\n",
    "    \n",
    "    return X_train,y_train,X_out,y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the metrics for a single large outer set, to obtain approximately converged metric values\n",
    "def compute_metrics(y_out, y_pred, verbose=False):\n",
    "    \"\"\"Computes the metrics\n",
    "    \"\"\"\n",
    "    cm_lim, metrics_lim = mmu.binary_metrics(y = y_out, yhat = y_pred)\n",
    "    prec_lim = metrics_lim[1]\n",
    "    rec_lim = metrics_lim[3]\n",
    "    if verbose:\n",
    "        print(f'Precision converges to {np.round(prec_mu,3)}, and recall converges to {np.round(rec_mu,3)}')\n",
    "    return cm_lim, prec_lim, rec_lim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sr_methods(X,y,model_class,train_size,model_kwargs = {}, n_bs_draws = 1, n_cv_splits = 6,random_state=None):\n",
    "    \"\"\"\n",
    "        Use various methods to estimate the distribution of the confusion matrix for a fixed train set. Includes bootstrapping the test set, k-fold cross-validation \n",
    "        and a Dirichlet-Multinomial Bayesian approach (Caelen 2017).\n",
    "\n",
    "        Parameters\n",
    "        X : np.ndarray[n,k]\n",
    "            Input features\n",
    "        y : np.ndarray[n]\n",
    "            Labels, 0 or 1\n",
    "        model_class : ...\n",
    "            model to be fitted and used to predict test labels\n",
    "        train_size : float\n",
    "            Fraction of observations to use for training, rest is used for testing. Determined by order; first `train_size` portion of observations are used for training.\n",
    "        model_kwargs : dict\n",
    "            Contains the arguments to intialize the model\n",
    "        n_bs_draws : int, default=1\n",
    "            number of bootstrap samples to draw\n",
    "        n_cv_splits : int, default=5\n",
    "            number of splits (k) used for k-fold cross-validation\n",
    "        random_state : int, default=None\n",
    "            State that determines the bootstrap draws, cross-validation splits, posterior fit for the Bayesian model, and potentially non-deterministic model training\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(random_state) # initialize random number generator\n",
    "    X_train, X_test = X[:train_size], X[train_size:] # Train/test splits for single test set methods\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    model = model_class(**model_kwargs).fit(X_train,y_train) \n",
    "    y_pred = model.predict(X_test)\n",
    "    cm_test = mmu.confusion_matrix(y_test,y_pred).flatten() # test set confusion matrix\n",
    "\n",
    "    cm_bs = sr.bstrp_cm(cm_test, n_bs_draws, rng)\n",
    "    cm_bs_y = sr.bstrp_y(X_test, y_test, model, n_draws=n_bs_draws, random_state=rng)\n",
    "    cm_cv = sr.kfold_cv_cm(X, y, model_class, model_kwargs, n_cv_splits,random_state=rng)\n",
    "    Dir_mn  = DirichletMultinomialConfusionMatrix(rng)\n",
    "    cm_DM = Dir_mn.fit_predict(cm_test)\n",
    "\n",
    "    return {'point_est' : cm_test, 'cm_bootstrap':cm_bs, 'y_bootstrap':cm_bs_y, 'Kfold_cv': cm_cv, 'Dir_Mn':cm_DM}"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# generator = BlobGenerator(data_size,int(test_size * n_sets),weights=[0.8,0.2])\n",
    "# X,y = generator.make_classification(random_state)\n",
    "X = np.arange(100).reshape((50,2))\n",
    "y = np.arange(1000)\n",
    "y.reshape(100,10)"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> NTB: found error using mmu.binary_metrics
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_iv(values, qrange=0.95, axis=None):\n",
    "    \"\"\"Produces an interval based on a median-centered quantile range\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    values : array-like,\n",
    "        contains the values to estimate the quantile-based interval from\n",
    "    qrange : float, optional\n",
    "        Fraction of observations the interval should include, by default 0.95\n",
    "    axis : , optional \n",
    "        Axis along which to compute the quantile-based interval\n",
    "    Returns\n",
    "    -------\n",
    "    _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    upper = np.quantile(values,1-(1-qrange)/2, axis=axis)\n",
    "    lower = np.quantile(values,(1-qrange)/2, axis=axis)\n",
    "    \n",
    "    return np.array([lower, upper])\n",
    "\n",
    "\n",
    "def frac_in_interval(values,interval):\n",
    "    return np.mean((interval[0]<values) & (values<interval[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prec_rec_CI(cm_dict,qrange=0.95):\n",
    "    \"\"\" From dictionary with confusion matrices, compute the quantile-based intervals for precision and recall\n",
    "    \n",
    "    Returns\n",
    "        Where dim 2 comprises of [prec_l, rec_l, prec_u, rec_u]\n",
    "    \"\"\"\n",
    "    method_keys = list(cm_dict.keys())\n",
    "    CI_array = np.zeros((len(method_keys),4))\n",
    "    for i,key in enumerate(method_keys):\n",
    "        scores = mmu.binary_metrics_confusion_matrices(cm_dict[key])[:,[1,3]] # Check which elements are precision and recall, check quantiles for multi dim arrays\n",
    "        bounds = quantile_iv(scores,axis=0).flatten() # save bounds of each method for each iteration, [prec_l, rec_l, prec_u, rec_u]\n",
    "        CI_array[i,:] = bounds\n",
    "    return CI_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_CI(\n",
    "    train_size=5000,\n",
    "    test_size=1000,\n",
    "    n_sets=1e4,\n",
    "    weights=[0.8,0.2],\n",
    "    model_class=LogisticRegression,\n",
    "    model_kwargs={'penalty':'none'},\n",
    "    n_bs_draws=1000,\n",
    "    n_cv_splits=6,\n",
    "    qrange=0.95,\n",
    "    random_state=None):\n",
    "    \n",
    "    \"\"\"performs a single run to evaluate confidence intervals\n",
    "    \"\"\"\n",
    "    \n",
    "    rng = np.random.default_rng(random_state)\n",
    "    # Generate the data, one known sample (X_in, y_in) and one enormous sample (X_out, y_out)\n",
    "    # gen_data(train_size=5000,test_size=1000,n_sets=1e4,weights=[0.8,0.2],random_state=None)\n",
    "    X_in, y_in, X_out, y_out = gen_data(train_size+test_size,test_size,n_sets,weights,rng)\n",
    "    X_train = X_in[:train_size]\n",
    "    y_train = y_in[:train_size]\n",
    "\n",
    "    # Fit model to train data and apply to huge sample to obtain population parameter proxies for cm, precision and recall\n",
    "    model = model_class(**model_kwargs).fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_out)\n",
    "    cm_lim, prec_mu, rec_mu = compute_metrics(y_out,y_pred)\n",
    "\n",
    "    # Apply methods, which return collections of confusion matrices\n",
    "    cm_dict = run_sr_methods(X_in, y_in, model_class, train_size, model_kwargs, n_bs_draws, n_cv_splits, random_state=rng)\n",
    "    point_est = cm_dict.pop('point_est')\n",
    "\n",
    "    # Estimate the quantile-based intervals for each method\n",
    "    CI_array = compute_prec_rec_CI(cm_dict,qrange=qrange)\n",
    "    \n",
    "    return CI_array, cm_lim, prec_mu, rec_mu # need to output (cm_lim, prec_mu, rec_mu) as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain confidence intervals for several data samples plus the proxy population parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_sims = 1\n",
    "n_methods = 4\n",
    "n_threads = None\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "thread_seeds = rng.integers(low=0, high=np.iinfo(np.uint64).max, size=n_sims, dtype=np.uint64)\n",
    "\n",
    "CI_array, cm_lim, prec_lim, rec_lim  = zip(*Parallel(n_jobs=n_threads)(delayed(eval_CI)(random_state=seed) for seed in thread_seeds))\n",
    "CI_array, cm_lim, prec_lim, rec_lim = np.array(CI_array), np.array(CI_array), np.array(prec_lim), np.array(rec_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and std width precision and recall\n",
    "\n",
    "prec_widths = CI_array[:,:,2] - CI_array[:,:,0] # widths over all iterations\n",
    "rec_widths = CI_array[:,:,3] - CI_array[:,:,1] \n",
    "\n",
    "prec_width_mean = prec_widths.mean(axis=0) # mean over iterations\n",
    "prec_width_std = prec_widths.std(axis=0)\n",
    "\n",
    "rec_width_mean = rec_widths.mean(axis=0) # standard deviation over iterations\n",
    "rec_width_std = rec_widths.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute coverage\n",
    "\n",
    "prec_coverage = ((prec_lim < CI_array[:,:,2].T) & (prec_lim > CI_array[:,:,0].T)).mean(axis=1)\n",
    "rec_coverage = ((rec_lim < CI_array[:,:,3].T) & (rec_lim > CI_array[:,:,1].T)).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = ['cm_bootstrap','y_bootstrap','Kfold_cv','Dir_Mn']\n",
    "data = [method_names, prec_width_mean, prec_width_std, prec_coverage, rec_width_mean, rec_width_std, rec_coverage]\n",
    "column_names = ['method', 'precision mean-width', 'precision std-width', 'precision coverage', 'recall mean-width', 'recall std-width', 'recall coverage']\n",
    "df = pd.DataFrame(data=data).T\n",
    "df.columns = column_names\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "\n",
    "# sns.kdeplot(prec_out,ax = ax1, label = 'precision distribution over holdout sets')\n",
    "# ax1.vlines(prec_mu,ymin = 0, ymax = 17,linestyle='dashed', label = 'converged precision')\n",
    "\n",
    "# sns.kdeplot(rec_out,ax = ax2, label = 'recall distribution over holdout sets',color = 'blue')\n",
    "# ax2.vlines(rec_mu,ymin = 0, ymax = 17,linestyle='dashed', label = 'converged recall',color= 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plots of the estimated predicton intervals of the precision, compared to the true out-of-sample metric distribution\n",
    "\n",
    "# sns.displot(precs_true, kind='kde')\n",
    "\n",
    "# plt.vlines(prec_test, 0, 12, label = 'Point-estimate')\n",
    "# plt.vlines(quantile_iv(precs_bs), 0, 12, colors = 'blue', linestyles='dashed',label='Bootstrap test set')\n",
    "# plt.vlines(quantile_iv(precs_cv), 0, 12, colors='green', linestyles='dashed',label='6-fold CV')\n",
    "# plt.vlines(quantile_iv(precs_dm), 0, 12, colors='purple', linestyles='dashed',label='Dirichlet-Multinomial')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plots of the estimated predicton intervals of the recall, compared to the true out-of-sample metric distribution\n",
    "\n",
    "# sns.displot(recs_true, kind='kde')\n",
    "\n",
    "# plt.vlines(rec_test, 0, 12, label = 'Point-estimate')\n",
    "# plt.vlines(quantile_iv(recs_bs), 0, 12, colors = 'blue', linestyles='dashed',label='Bootstrap test set')\n",
    "# plt.vlines(quantile_iv(recs_cv), 0, 12, colors='green', linestyles='dashed',label='6-fold CV')\n",
    "# plt.vlines(quantile_iv(recs_dm), 0, 12, colors='purple', linestyles='dashed',label='Dirichlet-Multinomial')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score_interval(est_values, true_values, qrange=0.95):\n",
    "#     lower,upper=quantile_iv(est_values,qrange=qrange)\n",
    "#     interval = (lower,upper)\n",
    "#     coverage = frac_in_interval(true_values,interval)\n",
    "#     width = interval[1]-interval[0]\n",
    "#     return [lower,upper,width,coverage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Performance of precision prediction interval\n",
    "\n",
    "# prec_iv_scores = []\n",
    "# for precs_est in [precs_bs,precs_cv,precs_dm]:\n",
    "#     prec_iv_scores.append(score_interval(precs_est,precs_true))\n",
    "# pd.DataFrame(prec_iv_scores,index = ['Bootstrap','6-fold CV','Dir-Mn'],columns = ['lower','upper','width','coverage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Performance of recall prediction interval\n",
    "\n",
    "# rec_iv_scores = []\n",
    "# for recs_est in [recs_bs,recs_cv,recs_dm]:\n",
    "#     rec_iv_scores.append(score_interval(recs_est,recs_true))\n",
    "# pd.DataFrame(rec_iv_scores,index = ['Bootstrap','6-fold CV','Dir-Mn'],columns = ['lower','upper','width','coverage'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50e2ea73d98f6ee2d543936d9795e87546ceaa579e11054f6af1573a6cde0e6b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
