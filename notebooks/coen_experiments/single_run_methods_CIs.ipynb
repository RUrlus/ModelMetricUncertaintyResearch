{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CC\"] = \"/opt/rh/devtoolset-10/root/usr/bin/gcc\"\n",
    "os.environ[\"CXX\"] = \"/opt/rh/devtoolset-10/root/usr/bin/g++\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will showcase the performance of a single run of test set - Bootstrap, k-fold cross validation, and a Dirichlet-Multinomial model for estimating the distribution of the confusion matrix in binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "import itertools as it\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import levene\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from mmur.simulators import LAlgorithm\n",
    "from mmur.generators import BlobGenerator\n",
    "from mmur.methods import single_run as sr\n",
    "from mmur import DirichletMultinomialConfusionMatrix\n",
    "from mmur import BetaBinomialConfusionMatrix\n",
    "import mmu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, consider only the randomness due to test set sampling. We keep a fixed train set, and attempt to predict how well a classifier predicts on new test data (from the same data distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sr_methods(X,y,model_class,train_size,model_kwargs = {},n_bs_draws = 1, n_cv_splits = 5,random_state=None):\n",
    "    \"\"\"\n",
    "        Use various methods to estimate the distribution of the confusion matrix for a fixed train set. Includes bootstrapping the test set, k-fold cross-validation \n",
    "        and a Dirichlet-Multinomial Bayesian approach (Caelen 2017).\n",
    "\n",
    "        Parameters\n",
    "        X : np.ndarray[n,k]\n",
    "            Input features\n",
    "\n",
    "        y : np.ndarray[n]\n",
    "            Labels, 0 or 1\n",
    "\n",
    "        model_class : ...\n",
    "            model to be fitted and used to predict test labels\n",
    "        \n",
    "        train_size : float\n",
    "            Fraction of observations to use for training, rest is used for testing. Determined by order; first `train_size` portion of observations are used for training.\n",
    "\n",
    "        model_kwargs : dict\n",
    "            Contains the arguments to intialize the model\n",
    "\n",
    "        n_bs_draws : int, default=1\n",
    "            number of bootstrap samples to draw\n",
    "        \n",
    "        n_cv_splits : int, default=5\n",
    "            number of splits (k) used for k-fold cross-validation\n",
    "\n",
    "        random_state : int, default=None\n",
    "            State that determines the bootstrap draws, cross-validation splits, posterior fit for the Bayesian model, and potentially non-deterministic model training\n",
    "    \"\"\"\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    model = model_class(**model_kwargs).fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm_test = confusion_matrix(y_test,y_pred).flatten()\n",
    "\n",
    "    cm_bs = sr.bstrp_cm(cm_test, n_bs_draws, random_state)\n",
    "    cm_cv = sr.kfold_cm(X, y, model_class, model_kwargs, n_cv_splits, random_state)\n",
    "    Dir_mn  = DirichletMultinomialConfusionMatrix(random_state)\n",
    "    cm_DM = Dir_mn.fit_predict(cm_test)\n",
    "\n",
    "    return cm_test, cm_bs, cm_cv, cm_DM"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# generator = BlobGenerator(data_size,int(test_size * n_sets),weights=[0.8,0.2])\n",
    "# X,y = generator.make_classification(random_state)\n",
    "X = np.arange(100).reshape((50,2))\n",
    "y = np.arange(1000)\n",
    "y.reshape(100,10)"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> NTB: found error using mmu.binary_metrics
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(train_size=5000,test_size=1000,n_sets=1e4,weights=[0.8,0.2],random_state=None):\n",
    "    \n",
    "    generator = BlobGenerator(train_size,int(test_size * n_sets),weights=[0.8,0.2])\n",
    "    X,y = generator.make_classification(random_state)\n",
    "\n",
    "    X_train, y_train = X[:train_size], y[:train_size]\n",
    "    X_out, y_out = X[train_size:].reshape((-1, test_size, 2)), y[train_size:].reshape((-1, test_size))\n",
    "    \n",
    "    return X_train,y_train,X_out,y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_cm(model_class,X_train,y_train,X_out,model_kwargs={}):\n",
    "\n",
    "    # Fit the model to the fixed train set\n",
    "    model = model_class(**model_kwargs).fit(X_train,y_train)\n",
    "\n",
    "    # Get predictions for all holdout sets\n",
    "    y_pred = model.predict(X_out.reshape((-1,2))).reshape((-1,1000))\n",
    "    \n",
    "    return y_pred, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_out,y_out = gen_data(5000,1000,10000,weights=[0.8,0.2],random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing out sr methods\n",
    "\n",
    "cms = sr.kfold_cv_cm(X_train,y_train,LogisticRegression,n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, model = sim_cm(\n",
    "    LogisticRegression, \n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_out,\n",
    "    model_kwargs = {'penalty':'none'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the confusion matrics and metrics for all the outer sets\n",
    "\n",
    "cm_out, metrics_out = mmu.binary_metrics_runs(\n",
    "    y_out, yhat=y_pred, obs_axis=1, fill=0.0, return_df=True\n",
    ")\n",
    "prec_out = metrics_out['pos.precision']\n",
    "rec_out = metrics_out['pos.recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the metrics for a single large outer set, to obtain approximately converged metric values\n",
    "\n",
    "cm_lim, metrics_lim = mmu.binary_metrics(y = y_out.flatten(), yhat = y_pred.flatten(),return_df=True)\n",
    "prec_mu = metrics_lim['pos.precision'].values[0]\n",
    "rec_mu = metrics_lim['pos.recall'].values[0]\n",
    "print(f'Precision converges to {np.round(prec_mu,3)}, and recall converges to {np.round(rec_mu,3)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "\n",
    "sns.kdeplot(prec_out,ax = ax1, label = 'precision distribution over holdout sets')\n",
    "ax1.vlines(prec_mu,ymin = 0, ymax = 17,linestyle='dashed', label = 'converged precision')\n",
    "\n",
    "sns.kdeplot(rec_out,ax = ax2, label = 'recall distribution over holdout sets',color = 'blue')\n",
    "ax2.vlines(rec_mu,ymin = 0, ymax = 17,linestyle='dashed', label = 'converged recall',color= 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bs = 100\n",
    "random_state = np.random.default_rng(1)\n",
    "cm = cm_out.to_numpy()[0]\n",
    "\n",
    "sr.bstrp_cm(cm,n_draws=n_bs,random_state=random_state)\n",
    "\n",
    "cm_cv = sr.kfold_cm(X, y, model_class, model_kwargs, n_cv_splits, random_state)\n",
    "Dir_mn  = DirichletMultinomialConfusionMatrix(random_state)\n",
    "cm_DM = Dir_mn.fit_predict(cm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_mn_cm(cm,random_state):\n",
    "    Dir_mn  = DirichletMultinomialConfusionMatrix(random_state)\n",
    "    cm_DM = Dir_mn.fit_predict(cm)\n",
    "    return cm_DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = -2\n",
    "n_cms = len(cm_out)\n",
    "rng = np.random.default_rng(1)\n",
    "thread_seeds = rng.integers(low=0, high=np.iinfo(\n",
    "            np.uint64).max, size=n_cms, dtype=np.uint64)\n",
    "cms_bs = Parallel(n_jobs = n_jobs)(delayed(sr.bstrp_cm)(cm,n_draws=n_bs,random_state=seed) for cm,seed in zip(cm_out,thread_seeds))\n",
    "\n",
    "thread_seeds = rng.integers(low=0, high=np.iinfo(\n",
    "            np.uint64).max, size=n_cms, dtype=np.uint64)\n",
    "cms_dm = Parallel(n_jobs=n_jobs)(delayed(dir_mn_cm)(cm,seed) for cm,seed in zip(cm_out,thread_seeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def quantile_iv(values,qrange = 0.95):\n",
    "#     \"\"\"produces an interval based on a median-centered quantile range\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     values : _type_\n",
    "#         _description_\n",
    "#     qrange : float, optional\n",
    "#         _description_, by default 0.95\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     _type_\n",
    "#         _description_\n",
    "#     \"\"\"\n",
    "#     upper = np.quantile(values,(1-qrange)/2)\n",
    "#     lower = np.quantile(values,1-(1-qrange)/2)\n",
    "#     return upper,lower\n",
    "\n",
    "\n",
    "# def frac_in_interval(values,interval):\n",
    "#     return np.mean((interval[0]<values) & (values<interval[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm_test, cm_bs, cm_cv, cm_DM = run_sr_methods(X_in,y_in,LogisticRegression,5000,{'penalty':'none'},1000,6,1)\n",
    "# prec_test, precs_bs, precs_cv, precs_dm = cms_to_precision(cm_test.reshape(-1,4))[0], cms_to_precision(cm_bs),cms_to_precision(cm_cv), cms_to_precision(cm_DM)\n",
    "# rec_test, recs_bs, recs_cv, recs_dm = cms_to_recall(cm_test.reshape(-1,4))[0], cms_to_recall(cm_bs),cms_to_recall(cm_cv), cms_to_recall(cm_DM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plots of the estimated predicton intervals of the precision, compared to the true out-of-sample metric distribution\n",
    "\n",
    "# sns.displot(precs_true, kind='kde')\n",
    "\n",
    "# plt.vlines(prec_test, 0, 12, label = 'Point-estimate')\n",
    "# plt.vlines(quantile_iv(precs_bs), 0, 12, colors = 'blue', linestyles='dashed',label='Bootstrap test set')\n",
    "# plt.vlines(quantile_iv(precs_cv), 0, 12, colors='green', linestyles='dashed',label='6-fold CV')\n",
    "# plt.vlines(quantile_iv(precs_dm), 0, 12, colors='purple', linestyles='dashed',label='Dirichlet-Multinomial')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plots of the estimated predicton intervals of the recall, compared to the true out-of-sample metric distribution\n",
    "\n",
    "# sns.displot(recs_true, kind='kde')\n",
    "\n",
    "# plt.vlines(rec_test, 0, 12, label = 'Point-estimate')\n",
    "# plt.vlines(quantile_iv(recs_bs), 0, 12, colors = 'blue', linestyles='dashed',label='Bootstrap test set')\n",
    "# plt.vlines(quantile_iv(recs_cv), 0, 12, colors='green', linestyles='dashed',label='6-fold CV')\n",
    "# plt.vlines(quantile_iv(recs_dm), 0, 12, colors='purple', linestyles='dashed',label='Dirichlet-Multinomial')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score_interval(est_values, true_values, qrange=0.95):\n",
    "#     lower,upper=quantile_iv(est_values,qrange=qrange)\n",
    "#     interval = (lower,upper)\n",
    "#     coverage = frac_in_interval(true_values,interval)\n",
    "#     width = interval[1]-interval[0]\n",
    "#     return [lower,upper,width,coverage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Performance of precision prediction interval\n",
    "\n",
    "# prec_iv_scores = []\n",
    "# for precs_est in [precs_bs,precs_cv,precs_dm]:\n",
    "#     prec_iv_scores.append(score_interval(precs_est,precs_true))\n",
    "# pd.DataFrame(prec_iv_scores,index = ['Bootstrap','6-fold CV','Dir-Mn'],columns = ['lower','upper','width','coverage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Performance of recall prediction interval\n",
    "\n",
    "# rec_iv_scores = []\n",
    "# for recs_est in [recs_bs,recs_cv,recs_dm]:\n",
    "#     rec_iv_scores.append(score_interval(recs_est,recs_true))\n",
    "# pd.DataFrame(rec_iv_scores,index = ['Bootstrap','6-fold CV','Dir-Mn'],columns = ['lower','upper','width','coverage'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50e2ea73d98f6ee2d543936d9795e87546ceaa579e11054f6af1573a6cde0e6b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
