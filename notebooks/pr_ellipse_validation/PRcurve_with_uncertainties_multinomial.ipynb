{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b679c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import histogrammar as hg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76feac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba6d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision-recall curve and f1\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    "from scipy.stats import chi2, norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b10a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kde_utils import kde_process_data, kde_make_transformers, kde_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bab561",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526e1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rc('font', size=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f33440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990099ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fake y and y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f677c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d5870",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = np.random.exponential(0.4, 2000)\n",
    "X0 = X0[X0 < 1]\n",
    "y0 = np.zeros(len(X0))\n",
    "\n",
    "X1 = np.random.exponential(0.25, 1000)\n",
    "X1 = 1. - X1[X1 < 1]\n",
    "y1 = np.ones(len(X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e39c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([X0, X1])\n",
    "y = np.concatenate([y0, y1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0121fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = hg.SparselyBin(binWidth=0.02)\n",
    "h0.fill.numpy(X0)\n",
    "h1 = hg.SparselyBin(binWidth=0.02)\n",
    "h1.fill.numpy(X1)\n",
    "\n",
    "h0.plot.matplotlib(alpha=0.5)\n",
    "h1.plot.matplotlib(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dbecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bb2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the precision-recall curves (sklearn)\n",
    "plt.figure(figsize=(12,7))\n",
    "no_skill = len(y[y==1]) / len(y)\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "plt.plot(recall, precision, marker='.', label='Classifier')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58bc644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64d6185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real y and y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a584f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 2 class dataset\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "# split into train/test sets\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "# fit a model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(trainX, trainy)\n",
    "# predict probabilities\n",
    "lr_probs = model.predict_proba(testX)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# predict class values\n",
    "yhat = model.predict(testX)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(testy, lr_probs)\n",
    "lr_f1, lr_auc = f1_score(testy, yhat), auc(recall, precision)\n",
    "# summarize scores\n",
    "print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588580b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the precision-recall curves\n",
    "plt.figure(figsize=(12,7))\n",
    "no_skill = len(testy[testy==1]) / len(testy)\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "plt.plot(recall, precision, marker='.', label='Classifier')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57904725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f029bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    y_true = y\n",
    "    y_prob = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446f7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = testy # [testy==1]\n",
    "y_prob = lr_probs # [testy==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b658010",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_true.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e72e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_true, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8213c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add zero threshold (missing by default?)\n",
    "thresholds = np.concatenate([[0.], thresholds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9572f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# Calculate Uncertainty bands\n",
    "\n",
    "N = len(y_true)\n",
    "\n",
    "# Getting TP, FN, FP\n",
    "# remark: computing them with metrics.confusion_matrix() takes too much time\n",
    "P = np.array([sum(y_true)] * len(thresholds))\n",
    "# we use \">= thr\" like in precision_recall_curve():\n",
    "TP = np.array([((y_prob >= thr) & y_true).sum() for thr in thresholds])\n",
    "PP = np.array([(y_prob >= thr).sum() for thr in thresholds])\n",
    "FN = P - TP\n",
    "FP = PP - TP\n",
    "TN = N - TP - FP - FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8e415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb5d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da20ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence limits for 1, 2, and 3 standard deviations in 1 dimension\n",
    "nstd1 = 2. * (norm.cdf(1) - 0.5)\n",
    "nstd2 = 2. * (norm.cdf(2) - 0.5)\n",
    "nstd3 = 2. * (norm.cdf(3) - 0.5)\n",
    "#print (nstd1, nstd2, nstd3)\n",
    "\n",
    "# confidence limits in two dimensions\n",
    "l90 = chi2.ppf(0.90, 2)\n",
    "# 68.3% = 1 std dev (1 dim)\n",
    "l68 = chi2.ppf(nstd1, 2)\n",
    "# 95.4% = 2 std dev (1 dim)\n",
    "l95 = chi2.ppf(nstd2, 2)\n",
    "# 99.7% = 3 std dev (1 dim)\n",
    "l99 = chi2.ppf(nstd3, 2)\n",
    "\n",
    "# scales with which to scale up r1 and r2\n",
    "scale1 = np.sqrt(l68)\n",
    "scale2 = np.sqrt(l95)\n",
    "scale3 = np.sqrt(l99)\n",
    "#print (scale1, scale2, scale3)\n",
    "\n",
    "print (l68, l90, l95, l99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2540400b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04e508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import xlogy\n",
    "\n",
    "def phat(rec, prec, x_tp, x_fp, x_tn, x_fn):\n",
    "    \"\"\"Fit probability parameters of confusion matrix under the constraint of \n",
    "    fixed recall and precision\n",
    "    \"\"\"\n",
    "    n4 = x_tp + x_fp + x_tn + x_fn\n",
    "    n3 = x_tp + x_fp + x_fn\n",
    "    alpha = (1-prec)/prec + (1-rec)/rec + 1\n",
    "    p_tp = (n3 / n4) * (1. / alpha)\n",
    "    p_fn = ((1-rec)/rec) * p_tp\n",
    "    p_fp = ((1-prec)/prec) * p_tp\n",
    "    p_tn = 1. - p_fn - p_fp - p_tp \n",
    "    # prevent negative values to due machine level noise\n",
    "    if isinstance(p_tn, np.ndarray):\n",
    "        p_tn[p_tn < 0] = 0\n",
    "    elif isinstance(p_tn, float) and p_tn < 0:\n",
    "        p_tn = 0.\n",
    "    return p_tp, p_fp, p_tn, p_fn\n",
    "\n",
    "def nll(rec, prec, x_tp, x_fp, x_tn, x_fn):\n",
    "    \"\"\"Return -2logp of multinomial distribution fixed at certain recall and precision\n",
    "\n",
    "    Two steps:\n",
    "    1. Fit with fixed recall and precision \n",
    "    2. Fit with all probability parameters free\n",
    "    \n",
    "    Return the difference in -2 log L\n",
    "    \"\"\"\n",
    "    # optimal fit of x\n",
    "    n4 = x_tp + x_fp + x_tn + x_fn\n",
    "    p_fn0 = x_fn / n4\n",
    "    p_tp0 = x_tp / n4\n",
    "    p_fp0 = x_fp / n4\n",
    "    p_tn0 = x_tn / n4\n",
    "    nll_minimum = -2 * xlogy(x_tp, p_tp0) - 2 * xlogy(x_fp, p_fp0) - 2 * xlogy(x_fn, p_fn0) - 2 * xlogy(x_tn, p_tn0)    \n",
    "\n",
    "    # fit of x constrained to recall and precision \n",
    "    p_tp, p_fp, p_tn, p_fn = phat(rec, prec, x_tp, x_fp, x_tn, x_fn)    \n",
    "    nll_value = -2 * xlogy(x_tp, p_tp) - 2 * xlogy(x_fp, p_fp) - 2 * xlogy(x_fn, p_fn) - 2 * xlogy(x_tn, p_tn)\n",
    "\n",
    "    # return the difference\n",
    "    return nll_value - nll_minimum\n",
    "\n",
    "def get_PRgrid(x_tp, x_fp, x_fn, nbins = 100, epsilon = 1e-4):\n",
    "    \"\"\"Make a rough estimate for the range of the precision-recall grid to scan\n",
    "    \"\"\"\n",
    "\n",
    "    # epsilon to prevent division by zero at edge\n",
    "    # Note: true values recall=100% or prec=100% can only hit boundary if fn=0 or fp=0\n",
    "    # else clip max values of recall and precision\n",
    "    max_rec_clip = 0 if x_fn == 0 else epsilon\n",
    "    max_prec_clip = 0 if x_fp == 0 else epsilon\n",
    "    \n",
    "    rec = x_tp / (x_tp + x_fn)\n",
    "    prec = x_tp / (x_tp + x_fp)  \n",
    "\n",
    "    # get rough estimates of sigma_rec and sigma_precision\n",
    "    # for rec=0,1 the uncertainty formula gives zero, correct for this \n",
    "    if rec == 0:\n",
    "        rec_for_sigma = 1 / (x_tp + x_fn)\n",
    "    elif rec == 1:\n",
    "        rec_for_sigma = (x_tp + x_fn - 1) / (x_tp + x_fn)\n",
    "    else:\n",
    "        rec_for_sigma = rec\n",
    "    # for prec=0,1 the uncertainty formula gives zero, correct for this \n",
    "    if prec == 0:\n",
    "        prec_for_sigma = 1 / (x_tp + x_fp)\n",
    "    elif prec == 1:\n",
    "        prec_for_sigma = (x_tp + x_fp - 1) / (x_tp + x_fp)\n",
    "    else:\n",
    "        prec_for_sigma = prec\n",
    "    # rough estimates of sigma_rec and sigma_precision    \n",
    "    sigma_rec = np.sqrt((rec_for_sigma*(1-rec_for_sigma))/(x_tp + x_fn))\n",
    "    sigma_prec = np.sqrt((prec_for_sigma*(1-prec_for_sigma))/(x_tp + x_fp))\n",
    "\n",
    "    # ranges of P and R to scan\n",
    "    rec_max = min(rec + 6 * sigma_rec, 1 - max_rec_clip)\n",
    "    rec_min = max(rec - 7 * sigma_rec, epsilon)\n",
    "    prec_max = min(prec + 6 * sigma_prec, 1 - max_prec_clip)\n",
    "    prec_min = max(prec - 7 * sigma_prec, epsilon)\n",
    "\n",
    "    # make PR grid to scan\n",
    "    rx = np.linspace(rec_min, rec_max, nbins)\n",
    "    py = np.linspace(prec_min, prec_max, nbins)\n",
    "    RX, PY = np.meshgrid(rx, py)\n",
    "    \n",
    "    return RX, PY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500c8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f9c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# For each point in the precision-recall curve plot an ellipse\n",
    "for i, (r, p, x_tp, x_fp, x_tn, x_fn) in enumerate(zip(recall, precision, TP, FP, TN, FN)):\n",
    "    RX, PY = get_PRgrid(x_tp, x_fp, x_fn)\n",
    "    chi2 = nll(RX, PY, x_tp, x_fp, x_tn, x_fn)\n",
    "    CS = ax.contour(RX, PY, chi2, levels=[l90])\n",
    "    \n",
    "# Plot precision-recall curve\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "ax.plot(recall, precision, label='observed values (test size = 500)', color='black')\n",
    "\n",
    "ax.set_xlim((-0.05, 1.05))\n",
    "ax.set_ylim((-0.05, 1.05))\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "#ax.set_title(f'Precision-Recall Curve ±1σ')\n",
    "ax.set_title(f'Precision-Recall Curve 90% CL')\n",
    "ax.legend(loc=\"lower left\")\n",
    "ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('PR_uncertainties.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a50e3a",
   "metadata": {},
   "source": [
    "### NOTE requires current HEAD of unstable branch of mmu\n",
    "\n",
    "install with:\n",
    "```\n",
    "pip install git+https://github.com/RUrlus/ModelMetricUncertainty@unstable\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e94bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmu\n",
    "from mmu.lib._mmu_core import multinomial_uncertainty_over_grid_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ac1efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sts\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2610f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_true, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a3661",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_grid = rec_grid = np.linspace(1e-6, 1 - 1e-6, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57085d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mats = mmu.confusion_matrices_thresholds(y=y_true, score=y_prob, thresholds=thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd115ab",
   "metadata": {},
   "source": [
    "### Quick and dirty implementation\n",
    "\n",
    "`multinomial_uncertainty_over_grid` only store the chi2 statistic in scores when it is smaller than the current value for that grid point.\n",
    "The function also only computes and potentially sets values in a grid with boundaries as determined by `n_sigmas` times the marginal std dev of the prec and rec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657169bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.ones((prec_grid.size, rec_grid.size)) * 1e4\n",
    "multinomial_uncertainty_over_grid_thresholds(\n",
    "    n_conf_mats=conf_mats.shape[0],\n",
    "    precs_grid=prec_grid,\n",
    "    recs_grid=rec_grid,\n",
    "    conf_mat=conf_mats,\n",
    "    scores=scores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccda4b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = sts.chi2(2).sf(np.abs(scores))\n",
    "\n",
    "df_grid = pd.DataFrame(\n",
    "    pvals,\n",
    "    columns=np.round(rec_grid, 4),\n",
    "    index=np.round(prec_grid, 4)\n",
    ").sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738dba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_idx = np.empty(recall.size, dtype=np.int64)\n",
    "for i, rec in enumerate(recall):\n",
    "    rec_idx[i] = np.abs(df_grid.columns - rec).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f57f9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_idx = np.empty(precision.size, dtype=np.int64)\n",
    "for i, prec in enumerate(precision):\n",
    "    prec_idx[i] = np.abs(df_grid.index - prec).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b57fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax = sns.heatmap(df_grid, ax=ax, vmin=0.0, vmax=1.0)\n",
    "ax.plot(rec_idx, prec_idx, c='black', label='$\\hat{p}, \\hat{r}$')\n",
    "ax.legend()\n",
    "ax.set_title(f'Multinomial uncertainty Precision-Recall')\n",
    "ax.set_xlabel('recall')\n",
    "ax.set_ylabel('precision')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118775c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax = sns.heatmap(df_grid, ax=ax, vmin=0.0, vmax=1.0)\n",
    "ax.scatter(rec_idx, prec_idx, c='black', label='$\\hat{p}, \\hat{r}$', s=10.0)\n",
    "ax.legend()\n",
    "ax.set_title(f'Multinomial uncertainty Precision-Recall')\n",
    "ax.set_xlabel('recall')\n",
    "ax.set_ylabel('precision')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34a5551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a348c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence limits for 1, 2, and 3 standard deviations in 1 dimension\n",
    "nstd1 = 2. * (norm.cdf(1) - 0.5)\n",
    "nstd2 = 2. * (norm.cdf(2) - 0.5)\n",
    "nstd3 = 2. * (norm.cdf(3) - 0.5)\n",
    "#print (nstd1, nstd2, nstd3)\n",
    "\n",
    "# confidence limits in two dimensions\n",
    "# 68.3% = 1 std dev (1 dim)\n",
    "l68 = chi2.ppf(nstd1, 2)\n",
    "# 95.4% = 2 std dev (1 dim)\n",
    "l95 = chi2.ppf(nstd2, 2)\n",
    "# 99.7% = 3 std dev (1 dim)\n",
    "l99 = chi2.ppf(nstd3, 2)\n",
    "\n",
    "print (l68, l95, l99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaefee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mats = mmu.confusion_matrices_thresholds(\n",
    "    y=y_true,\n",
    "    score=y_prob,\n",
    "    thresholds=np.linspace(1e-4, 1 - 1e-4, 1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179cda4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.ones((prec_grid.size, rec_grid.size)) * 1e4\n",
    "multinomial_uncertainty_over_grid_thresholds(\n",
    "    n_conf_mats=conf_mats.shape[0],\n",
    "    precs_grid=prec_grid,\n",
    "    recs_grid=rec_grid,\n",
    "    conf_mat=conf_mats,\n",
    "    scores=scores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203e82b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RX, PY = np.meshgrid(rec_grid, prec_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be18d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot both sets of contours\n",
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "CS = ax.contour(RX, PY, scores, levels=[l68, l95, l99])\n",
    "ax.clabel(CS, inline=True, fontsize=10)\n",
    "ax.plot(recall, precision)\n",
    "ax.grid()\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_ylim(0.0, 1.01)\n",
    "\n",
    "ax.plot(rec, prec,'ro') \n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'PR_exclusion_contours_{x_fp:.1f}FP.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
