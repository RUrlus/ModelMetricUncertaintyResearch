{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b679c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import histogrammar as hg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76feac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba6d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision-recall curve and f1\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    "from scipy.stats import chi2, norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b10a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmur.stats.kde_utils import kde_process_data, kde_make_transformers, kde_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bab561",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526e1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f33440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990099ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fake y and y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f677c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d5870",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = np.random.exponential(0.4, 2000)\n",
    "X0 = X0[X0 < 1]\n",
    "y0 = np.zeros(len(X0))\n",
    "\n",
    "X1 = np.random.exponential(0.25, 1000)\n",
    "X1 = 1. - X1[X1 < 1]\n",
    "y1 = np.ones(len(X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e39c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([X0, X1])\n",
    "y = np.concatenate([y0, y1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0121fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = hg.SparselyBin(binWidth=0.02)\n",
    "h0.fill.numpy(X0)\n",
    "h1 = hg.SparselyBin(binWidth=0.02)\n",
    "h1.fill.numpy(X1)\n",
    "\n",
    "h0.plot.matplotlib(alpha=0.5)\n",
    "h1.plot.matplotlib(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dbecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bb2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the precision-recall curves (sklearn)\n",
    "plt.figure(figsize=(12,7))\n",
    "no_skill = len(y[y==1]) / len(y)\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "plt.plot(recall, precision, marker='.', label='Classifier')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58bc644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64d6185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real y and y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a584f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 2 class dataset\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "# split into train/test sets\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "# fit a model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(trainX, trainy)\n",
    "# predict probabilities\n",
    "lr_probs = model.predict_proba(testX)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# predict class values\n",
    "yhat = model.predict(testX)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(testy, lr_probs)\n",
    "lr_f1, lr_auc = f1_score(testy, yhat), auc(recall, precision)\n",
    "# summarize scores\n",
    "print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588580b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the precision-recall curves\n",
    "plt.figure(figsize=(12,7))\n",
    "no_skill = len(testy[testy==1]) / len(testy)\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "plt.plot(recall, precision, marker='.', label='Classifier')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57904725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f029bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    y_true = y\n",
    "    y_prob = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446f7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = testy # [testy==1]\n",
    "y_prob = lr_probs # [testy==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b658010",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_true.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e72e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_true, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8213c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add zero threshold (missing by default?)\n",
    "thresholds = np.concatenate([[0.], thresholds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9572f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# Calculate Uncertainty bands\n",
    "\n",
    "N = len(y_true)\n",
    "\n",
    "# Getting TP, FN, FP\n",
    "# remark: computing them with metrics.confusion_matrix() takes too much time\n",
    "P = np.array([sum(y_true)] * len(thresholds))\n",
    "# we use \">= thr\" like in precision_recall_curve():\n",
    "TP = np.array([((y_prob >= thr) & y_true).sum() for thr in thresholds])\n",
    "PP = np.array([(y_prob >= thr).sum() for thr in thresholds])\n",
    "FN = P - TP\n",
    "FP = PP - TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8e415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef266be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial derivatives\n",
    "# tpr == recall = TP/P = TP/(TP + FN)\n",
    "# precision == positive predictive value = TP/PP = TP/(TP + FP)\n",
    "d_recall_d_TP = FN / (FN + TP)**2\n",
    "d_recall_d_FN = - TP / (FN + TP)**2\n",
    "d_precision_d_TP = FP / (FP + TP)**2\n",
    "d_precision_d_FP = - TP / (FP + TP)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c138a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_to_one(x, value=0):\n",
    "    xp = x.copy().astype(float)\n",
    "    xp[xp == 0] = value\n",
    "    return xp\n",
    "\n",
    "var_TP = N * (zero_to_one(TP)/N) * (1 - (zero_to_one(TP)/N))\n",
    "var_FN = N * (zero_to_one(FN)/N) * (1 - (zero_to_one(FN)/N))\n",
    "var_FP = N * (zero_to_one(FP)/N) * (1 - (zero_to_one(FP)/N))\n",
    "\n",
    "covar_TPFP = -N * (zero_to_one(TP)/N) * (zero_to_one(FP)/N)\n",
    "covar_TPFN = -N * (zero_to_one(TP)/N) * (zero_to_one(FN)/N)\n",
    "covar_FPFN = -N * (zero_to_one(FP)/N) * (zero_to_one(FN)/N)\n",
    "\n",
    "var_precision = (d_precision_d_TP ** 2) * var_TP + (d_precision_d_FP ** 2) * var_FP + 2 * d_precision_d_TP * d_precision_d_FP * covar_TPFP\n",
    "var_recall = (d_recall_d_TP ** 2) * var_TP + (d_recall_d_FN ** 2) * var_FN + 2 * d_recall_d_TP * d_recall_d_FN * covar_TPFN\n",
    "covar_recall_precision = d_recall_d_TP * d_precision_d_TP * var_TP + d_recall_d_TP * d_precision_d_FP * covar_TPFP + d_recall_d_FN * d_precision_d_TP * covar_TPFN + d_recall_d_FN * d_precision_d_FP * covar_FPFN\n",
    "\n",
    "#corrl_recall_precision = covar_recall_precision / np.sqrt(var_recall * var_precision)\n",
    "\n",
    "# Angle and lambdas\n",
    "# based on https://cookierobotics.com/007/ :\n",
    "a = var_recall  # cov[0][0]\n",
    "c = var_precision  # cov[1][1]\n",
    "b = covar_recall_precision  # cov[1][0]\n",
    "\n",
    "lambda1 = (a+c)/2 + np.sqrt(((a-c)/2)**2 + b**2)\n",
    "lambda2 = (a+c)/2 - np.sqrt(((a-c)/2)**2 + b**2)\n",
    "\n",
    "def calculate_theta(lambda1, a, b, c):\n",
    "    if b == 0 and a >= c:\n",
    "        return 0.\n",
    "    elif b == 0 and a < c:\n",
    "        return np.pi / 2.\n",
    "    else:\n",
    "        return np.arctan2(lambda1 - a, b)\n",
    "\n",
    "theta = np.vectorize(calculate_theta)(lambda1, a, b, c)\n",
    "angle = theta / np.pi * 180\n",
    "\n",
    "# Radii of the ellipse\n",
    "recall_r = np.sqrt(lambda1)\n",
    "precision_r = np.sqrt(lambda2)\n",
    "\n",
    "\n",
    "# Get the scale for 2 degrees of freedom confidence interval\n",
    "# We use chi2 because the equation of an ellipse is a sum of squared variable,\n",
    "# more details here https://www.visiondummy.com/2014/04/draw-error-ellipse-representing-covariance-matrix/\n",
    "norm_nstd = 1  # number of standard deviation\n",
    "norm_pct = 2. * (norm.cdf(norm_nstd) - 0.5)\n",
    "chi2_quantile = chi2.ppf(norm_pct, 2)\n",
    "\n",
    "# 90% CL \n",
    "chi2_quantile = chi2.ppf(0.9, 2)\n",
    "scale = np.sqrt(chi2_quantile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f9c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# For each point in the precision-recall curve plot an ellipse\n",
    "for i, (r, p, r_r, p_r, a) in enumerate(zip(recall, precision, recall_r, precision_r, angle)):\n",
    "    # we multiply the radius by 2 because width and height are diameters\n",
    "    ellipse = matplotlib.patches.Ellipse(\n",
    "        (r, p), width=2*scale*r_r, height=2*scale*p_r, angle=a, alpha=0.5) # adjust_lightness(cmap(0), 1.5))\n",
    "    ax.add_patch(ellipse)\n",
    "\n",
    "idx = -36\n",
    "r, p, r_r, p_r, a = recall[idx], precision[idx], recall_r[idx], precision_r[idx], angle[idx]\n",
    "ellipse = matplotlib.patches.Ellipse((r, p), width=2*scale*r_r, height=2*scale*p_r, angle=a, alpha=0.5, color='orange')\n",
    "ax.add_patch(ellipse)\n",
    "\n",
    "r, p, r_r, p_r, a = recall[40], precision[40], recall_r[40], precision_r[40], angle[40]\n",
    "ellipse = matplotlib.patches.Ellipse((r, p), width=2*scale*r_r, height=2*scale*p_r, angle=a, alpha=0.5, color='orange')\n",
    "ax.add_patch(ellipse)\n",
    "\n",
    "r, p, r_r, p_r, a = recall[int(N/2)], precision[int(N/2)], recall_r[int(N/2)], precision_r[int(N/2)], angle[int(N/2)]\n",
    "ellipse = matplotlib.patches.Ellipse((r, p), width=2*scale*r_r, height=2*scale*p_r, angle=a, alpha=0.5, color='orange')\n",
    "ax.add_patch(ellipse)\n",
    "\n",
    "# Plot precision-recall curve\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "ax.plot(recall, precision, label='classifier', color='black')\n",
    "\n",
    "rec1 = matplotlib.patches.Rectangle([0, 1.], 1.01, 0.1, ec=\"none\", color = 'white')\n",
    "rec2 = matplotlib.patches.Rectangle([1, 0.], 0.1, 1.01, ec=\"none\", color = 'white')\n",
    "ax.add_patch(rec1)\n",
    "ax.add_patch(rec2)\n",
    "\n",
    "ax.set_xlim((0, 1.01))\n",
    "ax.set_ylim((0, 1.01))\n",
    "ax.set_xlabel('Recall (True Positive Rate)')\n",
    "ax.set_ylabel('Precision (1-FDR)')\n",
    "#ax.set_title(f'Precision-Recall Curve ±1σ')\n",
    "ax.set_title(f'Precision-Recall Curve 90% CL')\n",
    "ax.legend(loc=\"lower left\")\n",
    "ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('PR_uncertainties.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ff8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5779d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when FP or FN is zero, calculate uncertainty band where FP or FN is set to 1. (conservative!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0733c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_to_one(x, value=1):\n",
    "    xp = x.copy().astype(float)\n",
    "    xp[xp == 0] = value\n",
    "    return xp\n",
    "\n",
    "var_TP = N * (zero_to_one(TP)/N) * (1 - (zero_to_one(TP)/N))\n",
    "var_FN = N * (zero_to_one(FN)/N) * (1 - (zero_to_one(FN)/N))\n",
    "var_FP = N * (zero_to_one(FP)/N) * (1 - (zero_to_one(FP)/N))\n",
    "\n",
    "covar_TPFP = -N * (zero_to_one(TP)/N) * (zero_to_one(FP)/N)\n",
    "covar_TPFN = -N * (zero_to_one(TP)/N) * (zero_to_one(FN)/N)\n",
    "covar_FPFN = -N * (zero_to_one(FP)/N) * (zero_to_one(FN)/N)\n",
    "\n",
    "var_precision = (d_precision_d_TP ** 2) * var_TP + (d_precision_d_FP ** 2) * var_FP + 2 * d_precision_d_TP * d_precision_d_FP * covar_TPFP\n",
    "var_recall = (d_recall_d_TP ** 2) * var_TP + (d_recall_d_FN ** 2) * var_FN + 2 * d_recall_d_TP * d_recall_d_FN * covar_TPFN\n",
    "covar_recall_precision = d_recall_d_TP * d_precision_d_TP * var_TP + d_recall_d_TP * d_precision_d_FP * covar_TPFP + d_recall_d_FN * d_precision_d_TP * covar_TPFN + d_recall_d_FN * d_precision_d_FP * covar_FPFN\n",
    "\n",
    "#corrl_recall_precision = covar_recall_precision / np.sqrt(var_recall * var_precision)\n",
    "\n",
    "# Angle and lambdas\n",
    "# based on https://cookierobotics.com/007/ :\n",
    "a = var_recall  # cov[0][0]\n",
    "c = var_precision  # cov[1][1]\n",
    "b = covar_recall_precision  # cov[1][0]\n",
    "\n",
    "lambda1 = (a+c)/2 + np.sqrt(((a-c)/2)**2 + b**2)\n",
    "lambda2 = (a+c)/2 - np.sqrt(((a-c)/2)**2 + b**2)\n",
    "\n",
    "def calculate_theta(lambda1, a, b, c):\n",
    "    if b == 0 and a >= c:\n",
    "        return 0.\n",
    "    elif b == 0 and a < c:\n",
    "        return np.pi / 2.\n",
    "    else:\n",
    "        return np.arctan2(lambda1 - a, b)\n",
    "\n",
    "theta = np.vectorize(calculate_theta)(lambda1, a, b, c)\n",
    "angle = theta / np.pi * 180\n",
    "\n",
    "# Radii of the ellipse\n",
    "recall_r = np.sqrt(lambda1)\n",
    "precision_r = np.sqrt(lambda2)\n",
    "\n",
    "\n",
    "# Get the scale for 2 degrees of freedom confidence interval\n",
    "# We use chi2 because the equation of an ellipse is a sum of squared variable,\n",
    "# more details here https://www.visiondummy.com/2014/04/draw-error-ellipse-representing-covariance-matrix/\n",
    "norm_nstd = 1  # number of standard deviation\n",
    "norm_pct = 2. * (norm.cdf(norm_nstd) - 0.5)\n",
    "chi2_quantile = chi2.ppf(norm_pct, 2)\n",
    "\n",
    "# 90% CL \n",
    "chi2_quantile = chi2.ppf(0.9, 2)\n",
    "scale = np.sqrt(chi2_quantile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfeea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# For each point in the precision-recall curve plot an ellipse\n",
    "for i, (r, p, r_r, p_r, a) in enumerate(zip(recall, precision, recall_r, precision_r, angle)):\n",
    "    # we multiply the radius by 2 because width and height are diameters\n",
    "    if r == 1 or p == 1:\n",
    "        ellipse = matplotlib.patches.Ellipse(\n",
    "            (r, p), width=2*scale*r_r, height=2*scale*p_r, angle=a, alpha=0.5, color='lightblue') # adjust_lightness(cmap(0), 1.5))        \n",
    "        ax.add_patch(ellipse)\n",
    "\n",
    "# For each point in the precision-recall curve plot an ellipse\n",
    "for i, (r, p, r_r, p_r, a) in enumerate(zip(recall, precision, recall_r, precision_r, angle)):\n",
    "    # we multiply the radius by 2 because width and height are diameters\n",
    "    if r != 1 and p != 1:\n",
    "        ellipse = matplotlib.patches.Ellipse(\n",
    "            (r, p), width=2*scale*r_r, height=2*scale*p_r, angle=a, alpha=0.5) # adjust_lightness(cmap(0), 1.5))\n",
    "        ax.add_patch(ellipse)\n",
    "    \n",
    "# Plot precision-recall curve\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "ax.plot(recall, precision, label='classifier', color='black')\n",
    "\n",
    "rec1 = matplotlib.patches.Rectangle([0, 1.], 1.01, 0.1, ec=\"none\", color = 'white')\n",
    "rec2 = matplotlib.patches.Rectangle([1, 0.], 0.1, 1.01, ec=\"none\", color = 'white')\n",
    "ax.add_patch(rec1)\n",
    "ax.add_patch(rec2)\n",
    "\n",
    "ax.set_xlim((0, 1.01))\n",
    "ax.set_ylim((0, 1.01))\n",
    "ax.set_xlabel('Recall (True Positive Rate)')\n",
    "ax.set_ylabel('Precision (1-FDR)')\n",
    "#ax.set_title(f'Precision-Recall Curve ±1σ')\n",
    "ax.set_title(f'Precision-Recall Curve 90% CL')\n",
    "ax.legend(loc=\"lower left\")\n",
    "ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('PR_uncertainties_0FP_conservative.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1690f8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (pyenv38)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
